{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SFBFiQlYlva"
      },
      "source": [
        "# Embedded ML - Lab 1.2: Model Compression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svldvvGfmN8q"
      },
      "source": [
        "In this lab you are asked to create a compressed verion of an ANNs model. You are not allowed to use ML libraries such as SciKit-learn, PyTorch or TensorFlow, but you are allowed to use standard libraries such as math, numpy and matplotlib if needed. You are given some code but you are expected to write some more and be able to explain and modify everything. This lab is essential for you to grasp the details of some of the most important techniques for compressing or making ML models more efficient: quantization and pruning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQK0RRRuY3rJ"
      },
      "source": [
        "### Learning outcomes\n",
        "\n",
        "\n",
        "* Explain the basic concepts of compression in ANNs\n",
        "* Apply range tuning and centering when doing quantization\n",
        "* Calculate and analyze the impact of quantization and pruning on memory and computing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8wat6Kxul5R"
      },
      "source": [
        "### Naive quantization\n",
        "Quantization means reducing the precission of model parameters and mainly targets weights, since they represent the most volumne of memory and processing in ANNs.\n",
        "\n",
        "Take the code from the last part of Lab 1.1 (MNIST model) and add methods to export and import weights to and from a binary file, making sure both processes work with your code in such a way that you don't have to train every time you want to run inference, but insted, the wieghts are loaded into the model when needed. Investigate which serialization/desarialization options exist in Python and choose one that you understand.\n",
        "\n",
        "Then, create two additional inference methods: FP16 and INT8. The FP16 method should treat all computations in the network involving the weights, as 16-bit floating-point. The INT8 method should work with 8-bit integers instead. In both cases, use the native datatype conversion methods. Investigate the NumPy methods available to enforce the desired datatypes.\n",
        "\n",
        "Run the two quantized models and compare them with the baseline in terms of model size, accuracy and latency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_size, output_size, dtype=np.float32):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dtype = dtype\n",
        "        self.init_weights()\n",
        "\n",
        "    def saturate(self, x):\n",
        "        \"\"\"Saturate values to the limits of the dtype.\"\"\"\n",
        "        if self.dtype == np.int8:\n",
        "            return np.clip(x, -128, 127).astype(np.int8)\n",
        "        return x.astype(self.dtype)\n",
        "\n",
        "    def init_weights(self):\n",
        "        self.weights_input_hidden = self.saturate(np.random.randn(self.input_size, self.hidden_size) * 0.01)\n",
        "        self.bias_input_hidden = self.saturate(np.zeros((1, self.hidden_size)))\n",
        "        self.weights_hidden_output = self.saturate(np.random.randn(self.hidden_size, self.output_size) * 0.01)\n",
        "        self.bias_hidden_output = self.saturate(np.zeros((1, self.output_size)))\n",
        "\n",
        "    def my_dot(self, A, B):\n",
        "        A = A.astype(np.int16 if self.dtype == np.int8 else self.dtype)\n",
        "        B = B.astype(np.int16 if self.dtype == np.int8 else self.dtype)\n",
        "        if A.ndim == 1:\n",
        "            A = A.reshape(1, -1)\n",
        "        result = np.zeros((A.shape[0], B.shape[1]), dtype=A.dtype)\n",
        "        for i in range(A.shape[0]):\n",
        "            for j in range(B.shape[1]):\n",
        "                for k in range(A.shape[1]):\n",
        "                    result[i, j] += A[i, k] * B[k, j]\n",
        "        return self.saturate(result)\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.astype(np.int16 if self.dtype == np.int8 else self.dtype)\n",
        "        self.hidden_input = self.my_dot(x, self.weights_input_hidden) + self.bias_input_hidden\n",
        "        self.hidden_output = self.saturate(self.sigmoid(self.hidden_input.astype(np.float32)))\n",
        "\n",
        "        self.final_input = self.my_dot(self.hidden_output, self.weights_hidden_output) + self.bias_hidden_output\n",
        "        self.output = self.saturate(self.sigmoid(self.final_input.astype(np.float32)))\n",
        "\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, x, y, output, learning_rate):\n",
        "        self.error = y - output\n",
        "        d_output = self.error * self.sigmoid_derivative(output.astype(np.float32))\n",
        "        d_output = self.saturate(d_output)\n",
        "\n",
        "        self.hidden_error = d_output.dot(self.weights_hidden_output.T)\n",
        "        d_hidden = self.hidden_error * self.sigmoid_derivative(self.hidden_output.astype(np.float32))\n",
        "        d_hidden = self.saturate(d_hidden)\n",
        "\n",
        "        self.weights_hidden_output += self.saturate(self.hidden_output.T.dot(d_output) * learning_rate)\n",
        "        self.bias_hidden_output += self.saturate(np.sum(d_output, axis=0, keepdims=True) * learning_rate)\n",
        "        self.weights_input_hidden += self.saturate(x.T.dot(d_hidden) * learning_rate)\n",
        "        self.bias_input_hidden += self.saturate(np.sum(d_hidden, axis=0, keepdims=True) * learning_rate)\n",
        "\n",
        "    def train(self, x, y, epochs, learning_rate):\n",
        "        error = 0\n",
        "        for epoch in range(epochs):\n",
        "            output = self.forward(x)\n",
        "            self.backward(x, y, output, learning_rate)\n",
        "            if epoch % 10 == 0:\n",
        "                error = np.mean(np.square(y - output))\n",
        "                print(f'Epoch {epoch}: Loss = {error:.4f}')\n",
        "        print(f'Epoch {epochs}: Loss = {error:.4f} ')\n",
        "\n",
        "    def save_all_weights(self, filename=\"model_weights.npz\"):\n",
        "        np.savez(\n",
        "            filename,\n",
        "            wih=self.weights_input_hidden,\n",
        "            bih=self.bias_input_hidden,\n",
        "            who=self.weights_hidden_output,\n",
        "            bho=self.bias_hidden_output\n",
        "        )\n",
        "\n",
        "    def load_all_weights(self, filename=\"model_weights.npz\"):\n",
        "        data = np.load(filename)\n",
        "        self.weights_input_hidden = self.saturate(data['wih'])\n",
        "        self.bias_input_hidden = self.saturate(data['bih'])\n",
        "        self.weights_hidden_output = self.saturate(data['who'])\n",
        "        self.bias_hidden_output = self.saturate(data['bho'])\n",
        "\n",
        "\n",
        "    def set_dtype(self, dtype):\n",
        "        self.dtype = dtype\n",
        "        self.weights_input_hidden = self.saturate(self.weights_input_hidden)\n",
        "        self.bias_input_hidden = self.saturate(self.bias_input_hidden)\n",
        "        self.weights_hidden_output = self.saturate(self.weights_hidden_output)\n",
        "        self.bias_hidden_output = self.saturate(self.bias_hidden_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading MNIST dataset...\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# === Load and preprocess MNIST dataset ===\n",
        "print(\"Loading MNIST dataset...\")\n",
        "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
        "X_data = mnist.data / 255.0\n",
        "y_data = mnist.target.astype(np.int32)\n",
        "\n",
        "# Reduce dataset size for faster training with random selection\n",
        "X_data = X_data[:1000]\n",
        "y_data = y_data[:1000]\n",
        "\n",
        "# One-hot encode labels\n",
        "encoder = OneHotEncoder(sparse_output=False, categories='auto')\n",
        "y_data_encoded = encoder.fit_transform(y_data.reshape(-1, 1))\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data_encoded, test_size=0.1, random_state=20)\n",
        "\n",
        "# === Run experiments with different hidden layer sizes ===\n",
        "h_size = 10\n",
        "results = []\n",
        "\n",
        "# Define parameters\n",
        "\n",
        " #Number of features (28*28=784)\n",
        "input_size = X_train.shape[1]\n",
        "# Number of classes (based on one-hot encoding)\n",
        "output_size = 10\n",
        "# Number of epochs\n",
        "epochs = 1000\n",
        "# Learning rate\n",
        "learning_rate = 0.01\n",
        "\n",
        "# \n",
        "labels = np.argmax(y_test, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training model with 10 hidden neurons...\n",
            "Epoch 0: Loss = 0.2511\n",
            "Epoch 10: Loss = 0.0904\n",
            "Epoch 20: Loss = 0.0897\n",
            "Epoch 30: Loss = 0.0882\n",
            "Epoch 40: Loss = 0.0830\n",
            "Epoch 50: Loss = 0.0732\n",
            "Epoch 60: Loss = 0.0655\n",
            "Epoch 70: Loss = 0.0589\n",
            "Epoch 80: Loss = 0.0513\n",
            "Epoch 90: Loss = 0.0478\n",
            "Epoch 100: Loss = 0.0394\n",
            "Epoch 110: Loss = 0.0350\n",
            "Epoch 120: Loss = 0.0315\n",
            "Epoch 130: Loss = 0.0285\n",
            "Epoch 140: Loss = 0.0258\n",
            "Epoch 150: Loss = 0.0239\n",
            "Epoch 160: Loss = 0.0212\n",
            "Epoch 170: Loss = 0.0190\n",
            "Epoch 180: Loss = 0.0174\n",
            "Epoch 190: Loss = 0.0162\n",
            "Epoch 200: Loss = 0.0147\n",
            "Epoch 210: Loss = 0.0136\n",
            "Epoch 220: Loss = 0.0127\n",
            "Epoch 230: Loss = 0.0118\n",
            "Epoch 240: Loss = 0.0110\n",
            "Epoch 250: Loss = 0.0102\n",
            "Epoch 260: Loss = 0.0096\n",
            "Epoch 270: Loss = 0.0090\n",
            "Epoch 280: Loss = 0.0086\n",
            "Epoch 290: Loss = 0.0081\n",
            "Epoch 300: Loss = 0.0077\n",
            "Epoch 310: Loss = 0.0073\n",
            "Epoch 320: Loss = 0.0070\n",
            "Epoch 330: Loss = 0.0067\n",
            "Epoch 340: Loss = 0.0064\n",
            "Epoch 350: Loss = 0.0061\n",
            "Epoch 360: Loss = 0.0058\n",
            "Epoch 370: Loss = 0.0056\n",
            "Epoch 380: Loss = 0.0053\n",
            "Epoch 390: Loss = 0.0051\n",
            "Epoch 400: Loss = 0.0050\n",
            "Epoch 410: Loss = 0.0048\n",
            "Epoch 420: Loss = 0.0046\n",
            "Epoch 430: Loss = 0.0045\n",
            "Epoch 440: Loss = 0.0043\n",
            "Epoch 450: Loss = 0.0042\n",
            "Epoch 460: Loss = 0.0041\n",
            "Epoch 470: Loss = 0.0040\n",
            "Epoch 480: Loss = 0.0039\n",
            "Epoch 490: Loss = 0.0038\n",
            "Epoch 500: Loss = 0.0037\n",
            "Epoch 510: Loss = 0.0036\n",
            "Epoch 520: Loss = 0.0036\n",
            "Epoch 530: Loss = 0.0035\n",
            "Epoch 540: Loss = 0.0034\n",
            "Epoch 550: Loss = 0.0034\n",
            "Epoch 560: Loss = 0.0033\n",
            "Epoch 570: Loss = 0.0033\n",
            "Epoch 580: Loss = 0.0032\n",
            "Epoch 590: Loss = 0.0031\n",
            "Epoch 600: Loss = 0.0031\n",
            "Epoch 610: Loss = 0.0030\n",
            "Epoch 620: Loss = 0.0030\n",
            "Epoch 630: Loss = 0.0030\n",
            "Epoch 640: Loss = 0.0029\n",
            "Epoch 650: Loss = 0.0029\n",
            "Epoch 660: Loss = 0.0028\n",
            "Epoch 670: Loss = 0.0028\n",
            "Epoch 680: Loss = 0.0028\n",
            "Epoch 690: Loss = 0.0027\n",
            "Epoch 700: Loss = 0.0027\n",
            "Epoch 710: Loss = 0.0027\n",
            "Epoch 720: Loss = 0.0026\n",
            "Epoch 730: Loss = 0.0026\n",
            "Epoch 740: Loss = 0.0025\n",
            "Epoch 750: Loss = 0.0025\n",
            "Epoch 760: Loss = 0.0024\n",
            "Epoch 770: Loss = 0.0024\n",
            "Epoch 780: Loss = 0.0023\n",
            "Epoch 790: Loss = 0.0023\n",
            "Epoch 800: Loss = 0.0023\n",
            "Epoch 810: Loss = 0.0022\n",
            "Epoch 820: Loss = 0.0022\n",
            "Epoch 830: Loss = 0.0022\n",
            "Epoch 840: Loss = 0.0022\n",
            "Epoch 850: Loss = 0.0021\n",
            "Epoch 860: Loss = 0.0021\n",
            "Epoch 870: Loss = 0.0021\n",
            "Epoch 880: Loss = 0.0021\n",
            "Epoch 890: Loss = 0.0021\n",
            "Epoch 900: Loss = 0.0020\n",
            "Epoch 910: Loss = 0.0020\n",
            "Epoch 920: Loss = 0.0020\n",
            "Epoch 930: Loss = 0.0020\n",
            "Epoch 940: Loss = 0.0020\n",
            "Epoch 950: Loss = 0.0019\n",
            "Epoch 960: Loss = 0.0019\n",
            "Epoch 970: Loss = 0.0019\n",
            "Epoch 980: Loss = 0.0019\n",
            "Epoch 990: Loss = 0.0019\n",
            "Epoch 1000: Loss = 0.0019 \n",
            "Predictions:  [5 8 7 6 4 7 7 4 9 4 1 6 8 6 8 7 9 4 5 6 1 7 1 4 8 9 1 6 8 8 1 1 0 1 7 4 1\n",
            " 6 1 0 6 2 3 0 5 5 4 5 0 3 7 2 5 4 2 1 1 5 5 6 3 5 5 1 0 7 8 9 6 1 5 0 5 0\n",
            " 7 0 1 3 6 1 6 5 1 0 4 0 2 6 0 0 3 6 0 1 5 5 0 3 2 5]\n",
            "Labels:  [3 8 7 6 8 7 7 4 9 4 1 8 2 6 8 7 9 4 5 6 1 7 1 1 8 9 1 6 8 8 2 1 0 1 7 7 1\n",
            " 6 1 6 6 2 3 0 5 5 4 5 0 3 9 2 5 4 2 1 7 5 5 6 3 5 5 1 0 7 8 9 6 1 0 0 5 0\n",
            " 7 0 1 9 6 1 6 5 1 0 4 0 2 6 0 0 3 6 0 1 5 5 0 3 2 3]\n",
            "\n",
            "Model Comparison Table:\n",
            " Hidden Neurons  Parameters  Forward Ops  Training Time (s)  Forward Time (ms)  Accuracy (%)\n",
            "             10       15900        15712            4061.88               4.61          87.0\n",
            "Saving weights to binary files...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(f\"\\nTraining model with {h_size} hidden neurons...\")\n",
        "nn = NeuralNetwork(input_size=input_size, hidden_size=h_size, output_size=output_size)\n",
        "\n",
        "start_train = time.time()\n",
        "nn.train(X_train, y_train, epochs=epochs, learning_rate=learning_rate)\n",
        "end_train = time.time()\n",
        "\n",
        "# Time one forward pass\n",
        "start_forward = time.time()\n",
        "output = nn.forward(X_test[:1])\n",
        "end_forward = time.time()\n",
        "\n",
        "# Predict and evaluate accuracy\n",
        "predictions = np.argmax(nn.forward(X_test), axis=1)\n",
        "print(\"Predictions: \", predictions)\n",
        "\n",
        "labels = np.argmax(y_test, axis=1)\n",
        "print(\"Labels: \", labels)\n",
        "accuracy = np.mean(predictions == labels) * 100\n",
        "\n",
        "# Count parameters and forward operations\n",
        "param_count = (2 * input_size * h_size) + (2 * h_size * output_size) + (h_size + output_size)\n",
        "forward_ops = 2*input_size*h_size + 3*h_size + 2\n",
        "\n",
        "results.append({\n",
        "    \"Hidden Neurons\": h_size,\n",
        "    \"Parameters\": param_count,\n",
        "    \"Forward Ops\": forward_ops,\n",
        "    \"Training Time (s)\": round(end_train - start_train, 2),\n",
        "    \"Forward Time (ms)\": round((end_forward - start_forward) * 1000, 2),\n",
        "    \"Accuracy (%)\": round(accuracy, 2)\n",
        "})\n",
        "\n",
        "# === Display results table ===\n",
        "df = pd.DataFrame(results)\n",
        "print(\"\\nModel Comparison Table:\")\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "# === Save weights to binary files ===\n",
        "print(\"Saving weights to binary files...\")\n",
        "nn.save_all_weights(\"weights_fp32.npz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Weights and biases range:\n",
            "FP32 Weights Input-Hidden:  -1.062898 1.2112243\n",
            "FP32 Bias Input-Hidden:  -0.9975036 0.49849313\n",
            "FP32 Weights Hidden-Output:  -6.2362213 4.951678\n",
            "FP32 Bias Hidden-Output:  -3.4558628 -0.7425632\n",
            "--------------------------------------------------\n",
            "FP16 Weights Input-Hidden:  -1.0625 1.211\n",
            "FP16 Bias Input-Hidden:  -0.9976 0.4985\n",
            "FP16 Weights Hidden-Output:  -6.234 4.953\n",
            "FP16 Bias Hidden-Output:  -3.455 -0.7427\n",
            "--------------------------------------------------\n",
            "INT8 Weights Input-Hidden:  -1 1\n",
            "INT8 Bias Input-Hidden:  0 0\n",
            "INT8 Weights Hidden-Output:  -6 4\n",
            "INT8 Bias Hidden-Output:  -3 0\n"
          ]
        }
      ],
      "source": [
        "#Load weights from binary file\n",
        "model_fp32 = NeuralNetwork(input_size=input_size, hidden_size=h_size, output_size=output_size, dtype=np.float32)\n",
        "model_fp32.load_all_weights(\"weights_fp32.npz\")\n",
        "\n",
        "model_fp16 = NeuralNetwork(input_size=input_size, hidden_size=h_size, output_size=output_size, dtype=np.float16)\n",
        "model_fp16.load_all_weights(\"weights_fp32.npz\")\n",
        "\n",
        "model_int8 = NeuralNetwork(input_size=input_size, hidden_size=h_size, output_size=output_size, dtype=np.int8)\n",
        "model_int8.load_all_weights(\"weights_fp32.npz\")\n",
        "\n",
        "# Print range of weights and biases\n",
        "print(\"\\nWeights and biases range:\")\n",
        "print(\"FP32 Weights Input-Hidden: \", model_fp32.weights_input_hidden.min(), model_fp32.weights_input_hidden.max())\n",
        "print(\"FP32 Bias Input-Hidden: \", model_fp32.bias_input_hidden.min(), model_fp32.bias_input_hidden.max())\n",
        "print(\"FP32 Weights Hidden-Output: \", model_fp32.weights_hidden_output.min(), model_fp32.weights_hidden_output.max())\n",
        "print(\"FP32 Bias Hidden-Output: \", model_fp32.bias_hidden_output.min(), model_fp32.bias_hidden_output.max())\n",
        "print(\"--------------------------------------------------\")\n",
        "print(\"FP16 Weights Input-Hidden: \", model_fp16.weights_input_hidden.min(), model_fp16.weights_input_hidden.max())\n",
        "print(\"FP16 Bias Input-Hidden: \", model_fp16.bias_input_hidden.min(), model_fp16.bias_input_hidden.max())\n",
        "print(\"FP16 Weights Hidden-Output: \", model_fp16.weights_hidden_output.min(), model_fp16.weights_hidden_output.max())\n",
        "print(\"FP16 Bias Hidden-Output: \", model_fp16.bias_hidden_output.min(), model_fp16.bias_hidden_output.max())\n",
        "print(\"--------------------------------------------------\")\n",
        "print(\"INT8 Weights Input-Hidden: \", model_int8.weights_input_hidden.min(), model_int8.weights_input_hidden.max())\n",
        "print(\"INT8 Bias Input-Hidden: \", model_int8.bias_input_hidden.min(), model_int8.bias_input_hidden.max())\n",
        "print(\"INT8 Weights Hidden-Output: \", model_int8.weights_hidden_output.min(), model_int8.weights_hidden_output.max())\n",
        "print(\"INT8 Bias Hidden-Output: \", model_int8.bias_hidden_output.min(), model_int8.bias_hidden_output.max())\n",
        "\n",
        "# # Multiply weights and biases by 10 for INT8 before loading from file with FP32\n",
        "# model_int8.weights_input_hidden = model_int8.saturate(model_fp32.weights_input_hidden * 10)\n",
        "# model_int8.bias_input_hidden = model_int8.saturate(model_fp32.bias_input_hidden * 10)\n",
        "# model_int8.weights_hidden_output = model_int8.saturate(model_fp32.weights_hidden_output * 10)\n",
        "# model_int8.bias_hidden_output = model_int8.saturate(model_fp32.bias_hidden_output * 10)\n",
        "\n",
        "# # Print range of weights and biases after scaling\n",
        "# print(\"\\nWeights and biases range after scaling:\")\n",
        "# print(\"INT8 Weights Input-Hidden: \", model_int8.weights_input_hidden.min(), model_int8.weights_input_hidden.max())\n",
        "# print(\"INT8 Bias Input-Hidden: \", model_int8.bias_input_hidden.min(), model_int8.bias_input_hidden.max())\n",
        "# print(\"INT8 Weights Hidden-Output: \", model_int8.weights_hidden_output.min(), model_int8.weights_hidden_output.max())\n",
        "# print(\"INT8 Bias Hidden-Output: \", model_int8.bias_hidden_output.min(), model_int8.bias_hidden_output.max())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model: FP32\n",
            "Predictions:  [5 8 7 6 4 7 7 4 9 4 1 6 8 6 8 7 9 4 5 6 1 7 1 4 8 9 1 6 8 8 1 1 0 1 7 4 1\n",
            " 6 1 0 6 2 3 0 5 5 4 5 0 3 7 2 5 4 2 1 1 5 5 6 3 5 5 1 0 7 8 9 6 1 5 0 5 0\n",
            " 7 0 1 3 6 1 6 5 1 0 4 0 2 6 0 0 3 6 0 1 5 5 0 3 2 5]\n",
            "Labels:  [3 8 7 6 8 7 7 4 9 4 1 8 2 6 8 7 9 4 5 6 1 7 1 1 8 9 1 6 8 8 2 1 0 1 7 7 1\n",
            " 6 1 6 6 2 3 0 5 5 4 5 0 3 9 2 5 4 2 1 7 5 5 6 3 5 5 1 0 7 8 9 6 1 0 0 5 0\n",
            " 7 0 1 9 6 1 6 5 1 0 4 0 2 6 0 0 3 6 0 1 5 5 0 3 2 3]\n",
            "\n",
            "Model: FP16\n",
            "Predictions:  [5 8 7 6 4 7 7 4 9 4 1 6 8 6 8 7 9 4 5 6 1 7 1 4 8 9 1 6 8 8 1 1 0 1 7 4 1\n",
            " 6 1 0 6 2 3 0 5 5 4 5 0 3 7 2 5 4 2 1 1 5 5 6 3 5 5 1 0 7 8 9 6 1 5 0 5 0\n",
            " 7 0 1 3 6 1 6 5 1 0 4 0 2 6 0 0 3 6 0 1 5 5 0 3 2 5]\n",
            "Labels:  [3 8 7 6 8 7 7 4 9 4 1 8 2 6 8 7 9 4 5 6 1 7 1 1 8 9 1 6 8 8 2 1 0 1 7 7 1\n",
            " 6 1 6 6 2 3 0 5 5 4 5 0 3 9 2 5 4 2 1 7 5 5 6 3 5 5 1 0 7 8 9 6 1 0 0 5 0\n",
            " 7 0 1 9 6 1 6 5 1 0 4 0 2 6 0 0 3 6 0 1 5 5 0 3 2 3]\n",
            "\n",
            "Model: INT8\n",
            "Predictions:  [2 2 0 0 2 0 2 0 0 1 2 2 2 0 2 2 0 2 0 0 2 0 0 0 2 0 0 0 2 2 2 2 2 2 0 2 2\n",
            " 0 0 1 2 2 0 0 2 2 2 0 0 0 2 2 0 2 0 0 0 2 2 2 1 0 1 0 2 0 0 2 0 1 0 2 2 2\n",
            " 2 0 2 0 0 0 0 2 0 2 2 0 2 2 0 0 2 2 2 2 2 0 2 0 0 2]\n",
            "Labels:  [3 8 7 6 8 7 7 4 9 4 1 8 2 6 8 7 9 4 5 6 1 7 1 1 8 9 1 6 8 8 2 1 0 1 7 7 1\n",
            " 6 1 6 6 2 3 0 5 5 4 5 0 3 9 2 5 4 2 1 7 5 5 6 3 5 5 1 0 7 8 9 6 1 0 0 5 0\n",
            " 7 0 1 9 6 1 6 5 1 0 4 0 2 6 0 0 3 6 0 1 5 5 0 3 2 3]\n",
            "\n",
            "Model Performance Comparison:\n",
            "Model  Forward Time All (ms)  Forward Time One (ms)  Accuracy (%)  Weights Size (KB)\n",
            " FP32                 972.96                 9.7296          87.0              31.09\n",
            " FP16                 552.26                 5.5226          87.0              15.55\n",
            " INT8                 558.24                 5.5824          13.0               7.77\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Crist\\AppData\\Local\\Temp\\ipykernel_9616\\2825271730.py:36: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-x))\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Input data for testing\n",
        "input_data_fp32 = X_test.astype(np.float32)\n",
        "input_data_fp16 = X_test.astype(np.float16)\n",
        "input_data_int8 = X_test.astype(np.int8)\n",
        "\n",
        "# Test the models with the same input data\n",
        "models = {\n",
        "    \"FP32\": model_fp32,\n",
        "    \"FP16\": model_fp16,\n",
        "    \"INT8\": model_int8\n",
        "}\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    start_forward = time.time()\n",
        "    output = model.forward(input_data_fp32 if model_name == \"FP32\" else input_data_fp16 if model_name == \"FP16\" else input_data_int8)\n",
        "    end_forward = time.time()\n",
        "\n",
        "    if model_name == \"INT8\":\n",
        "        # Decuantize the output for INT8 model to float32 for accuracy calculation\n",
        "        output = output.astype(np.float32) \n",
        "\n",
        "    # Calculate accuracy\n",
        "    predictions = np.argmax(output, axis=1)\n",
        "    accuracy = np.mean(predictions == labels) * 100\n",
        "\n",
        "    print(f\"\\nModel: {model_name}\")\n",
        "    print(\"Predictions: \", predictions)\n",
        "    print(\"Labels: \", labels)\n",
        "\n",
        "    # Get size of weights and biases in MB\n",
        "    weights_size = (model.weights_input_hidden.nbytes + model.bias_input_hidden.nbytes +\n",
        "                    model.weights_hidden_output.nbytes + model.bias_hidden_output.nbytes) / (1024)\n",
        "\n",
        "\n",
        "    results.append({\n",
        "        \"Model\": model_name,\n",
        "        \"Forward Time All (ms)\": round((end_forward - start_forward) * 1000, 2),\n",
        "        \"Forward Time One (ms)\": round((end_forward - start_forward) * 1000, 2) / len(X_test),\n",
        "        \"Accuracy (%)\": round(accuracy, 2),\n",
        "        \"Weights Size (KB)\": round(weights_size, 2)\n",
        "    })\n",
        "    \n",
        "\n",
        "# === Display results table ===\n",
        "df = pd.DataFrame(results)\n",
        "print(\"\\nModel Performance Comparison:\")\n",
        "print(df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpQD3Y7a_wFa"
      },
      "source": [
        "### Range tuning and centering\n",
        "For quantization to be effective, you should smartly choose the range of numbers you will code with the fewer bits available after quantization. To do so, you should evaluate the dynamic ranges of the variables to be quantized and map the values using that as the full range.\n",
        "\n",
        "Make a histogram plot of the model weights in order to verify their range. Then write a function to quantize the weights stored in the exported binary file to INT8 and store the resulting weights in another file. Finally, run again the INT8 quantized inference with the newly computed weights and compare with the previous versions using the same metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDMywPk5qZiV"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/YAAAIjCAYAAACpnIB8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB2w0lEQVR4nO3deVxU1f/H8fcAM6yCu2iikJpb7pqSqbjiklnaqiWYZZpLappfv1lqWZa737SsXwlW2mJlizsumGsuSZr2tTLNSlArFdkHZn5/8GV0QhEQHC6+no/HfXjm3DN3PnfmMJ7PnLuY7Ha7XQAAAAAAwJDcXB0AAAAAAAAoPBJ7AAAAAAAMjMQeAAAAAAADI7EHAAAAAMDASOwBAAAAADAwEnsAAAAAAAyMxB4AAAAAAAMjsQcAAAAAwMBI7AEAAAAAMDASewBAqRAcHKzIyEhXh1HqzZw5UzfffLPc3d3VtGlTV4eTS2xsrEwmk2JjYwv83OjoaJlMJh0/frzI4yqMsLAwhYWFFfq5t956a9EGBAAosUjsAQAlTk6CtXfv3suuL6qkZfXq1ZoyZco1b+dGsX79ej3zzDNq27atoqKi9PLLL1+xbWRkpEwmk/z9/ZWamppr/U8//SSTySSTyaRZs2YVZ9hFasaMGTKZTNq/f79Tvd1uV7ly5WQymXTs2DGndWlpafL09FT//v2vZ6j5cvLkSU2ZMkVxcXGuDgUAcA08XB0AAABF4ciRI3JzK9jv1atXr9bChQtJ7vNp06ZNcnNz0zvvvCOLxXLV9h4eHkpJSdFXX32l+++/32nd0qVL5eXlpbS0tOIKt1jccccdkqRt27apWbNmjvpDhw7p3Llz8vDw0Pbt2xUSEuJYt2fPHmVkZDiem1/r168vmqDzcPLkSU2dOlXBwcEl8ggMAED+MGMPACgVPD09ZTabXR1GgSQnJ7s6hAI5ffq0vL2985XUS9mfSefOnfXBBx/kWrds2TL16tWrqEMsdi1btpSXl5e2bdvmVL99+3ZVqFBBnTt3zrUu53FBE3uLxZLv9xoAcGMjsQcAlAr/PMfearVq6tSpqlOnjry8vFShQgXdcccdiomJkZR9qPjChQslyXFIuMlkcjw/OTlZTz/9tIKCguTp6am6detq1qxZstvtTq+bmpqqUaNGqWLFiipTpozuuusu/fHHHzKZTE5HAkyZMkUmk0mHDx9W//79Va5cOUeid+DAAUVGRurmm2+Wl5eXAgMD9eijj+qvv/5yeq2cbfz44496+OGHFRAQoEqVKum5556T3W7Xb7/9pj59+sjf31+BgYGaPXt2vt67zMxMvfjii6pVq5Y8PT0VHBysf//730pPT3e0MZlMioqKUnJysuO9io6Ovuq2+/fvrzVr1ujcuXOOuj179uinn3664qHpv/zyi+677z6VL19ePj4+atOmjVatWpWr3e+//667775bvr6+qly5ssaMGeMU86W++eYbde/eXQEBAfLx8VGHDh20ffv2q8b/TxaLRa1atcr13O3btys0NFRt27a97LqyZcs6Th+x2WyaN2+eGjZsKC8vL1WpUkVPPPGEzp496/S8y51j/+uvv+quu+5y2ud169Zd8boChw8fVseOHeXj46ObbrpJM2bMcKyLjY1Vq1atJEmDBg3K9bn+9NNP6tevnwIDA+Xl5aXq1avrwQcf1Pnz5wv8vgEAiheH4gMASqzz58/rzz//zFVvtVqv+twpU6Zo+vTpeuyxx3TbbbcpMTFRe/fu1bfffquuXbvqiSee0MmTJxUTE6P33nvP6bl2u1133XWXNm/erMGDB6tp06Zat26dxo8frz/++ENz5851tI2MjNTHH3+sRx55RG3atNGWLVvynIm+7777VKdOHb388suOHwliYmL0yy+/aNCgQQoMDNShQ4f01ltv6dChQ9q1a5fTDw6S9MADD6h+/fp65ZVXtGrVKk2bNk3ly5fXm2++qU6dOunVV1/V0qVLNW7cOLVq1Urt27fP87167LHHtGTJEt177716+umn9c0332j69On64YcftGLFCknSe++9p7feeku7d+/W22+/LUm6/fbbr/o59O3bV0OHDtVnn32mRx99VFL2bH29evXUvHnzXO1PnTql22+/XSkpKRo1apQqVKigJUuW6K677tInn3yie+65R1L2DyqdO3fWiRMnNGrUKFWrVk3vvfeeNm3alGubmzZtUo8ePdSiRQtNnjxZbm5uioqKUqdOnbR161bddtttV92PS91xxx3aunWrjh8/ruDgYEnZyXtOX5s8ebLOnTunsmXLym63a8eOHQoNDXWcKvLEE08oOjpagwYN0qhRo3Ts2DEtWLBA+/fv1/bt26945ElycrI6deqk+Ph4PfXUUwoMDNSyZcu0efPmy7Y/e/asunfvrr59++r+++/XJ598ogkTJqhRo0bq0aOH6tevrxdeeEHPP/+8hgwZonbt2knK/lwzMjIUHh6u9PR0jRw5UoGBgfrjjz+0cuVKnTt3TgEBAQV6zwAAxcwOAEAJExUVZZeU59KwYUOn59SsWdMeERHheNykSRN7r1698nyd4cOH2y/3X+Hnn39ul2SfNm2aU/29995rN5lM9p9//tlut9vt+/bts0uyjx492qldZGSkXZJ98uTJjrrJkyfbJdkfeuihXK+XkpKSq+6DDz6wS7J//fXXubYxZMgQR11mZqa9evXqdpPJZH/llVcc9WfPnrV7e3s7vSeXExcXZ5dkf+yxx5zqx40bZ5dk37Rpk6MuIiLC7uvrm+f2Ltf23nvvtXfu3Nlut9vtWVlZ9sDAQPvUqVPtx44ds0uyz5w50/G80aNH2yXZt27d6qi7cOGCPSQkxB4cHGzPysqy2+12+7x58+yS7B9//LGjXXJysr127dp2SfbNmzfb7Xa73Waz2evUqWMPDw+322w2R9uUlBR7SEiIvWvXro66nH537NixPPdt1apVdkn29957z2632+3x8fF2SfYtW7bYL1y4YHd3d7evWrXKbrfb7d9//71dkv2ll16y2+12+9atW+2S7EuXLnXa5tq1a3PVd+jQwd6hQwfH49mzZ9sl2T///HNHXWpqqr1evXpO+5zzXEn2d99911GXnp5uDwwMtPfr189Rt2fPHrske1RUlFM8+/fvt0uyL1++PM/3AgBQMnAoPgCgxFq4cKFiYmJyLY0bN77qc8uWLatDhw7pp59+KvDrrl69Wu7u7ho1apRT/dNPPy273a41a9ZIktauXStJevLJJ53ajRw58orbHjp0aK46b29vRzktLU1//vmn2rRpI0n69ttvc7V/7LHHHGV3d3e1bNlSdrtdgwcPdtSXLVtWdevW1S+//HLFWKTsfZWksWPHOtU//fTTknTZQ+ALqn///oqNjVVCQoI2bdqkhISEKx6Gv3r1at12221O56P7+flpyJAhOn78uA4fPuxoV7VqVd17772Odj4+PhoyZIjT9uLi4hyH/f/111/6888/9eeffyo5OVmdO3fW119/LZvNVqD9uf322+Xm5uY4dz5nlr1Vq1by8/NT48aNHYfj5/ybsz/Lly9XQECAunbt6ojlzz//VIsWLeTn53fF2Xcpu7/ddNNNuuuuuxx1Xl5eevzxxy/b3s/PTw8//LDjscVi0W233XbVPiHJMSO/bt06paSkXLU9AMC1OBQfAFBi3XbbbWrZsmWu+nLlyl32EP1LvfDCC+rTp49uueUW3XrrrerevbseeeSRfP0o8Ouvv6patWoqU6aMU339+vUd63P+dXNzc7oCuiTVrl37itv+Z1tJ+vvvvzV16lR9+OGHOn36tNO6y53PXKNGDafHAQEB8vLyUsWKFXPV//M8/X/K2Yd/xhwYGKiyZcs69vVa9OzZU2XKlNFHH32kuLg4tWrVSrVr177s/eJ//fVXtW7dOlf9pe/9rbfeql9//VW1a9fOdZpC3bp1nR7n/LATERFxxfjOnz+vcuXK5Xt/ypYtq4YNGzol782aNXP8QHP77bc7rctJqHPiOX/+vCpXrnzZbf/z87/Ur7/+qlq1auXa5yv1t+rVq+dqW65cOR04cOCq+xgSEqKxY8dqzpw5Wrp0qdq1a6e77rrLcW0HAEDJQmIPACiV2rdvr6NHj+qLL77Q+vXr9fbbb2vu3LlatGiR04z39Xbp7HyO+++/Xzt27ND48ePVtGlT+fn5yWazqXv37pedTXZ3d89XnaRcF/u7kn8mgEXJ09NTffv21ZIlS/TLL79c19sL5rx/M2fOvOLt3Pz8/Aq83TvuuEOLFi3SuXPntH37dqfrDdx+++1avHixrFartm3bphYtWsjLy8sRT+XKlbV06dLLbrdSpUoFjuVKrrVPzJ49W5GRkY6/oVGjRmn69OnatWuXqlevXmRxAgCuHYk9AKDUKl++vAYNGqRBgwYpKSlJ7du315QpUxyJ/ZWS2Zo1a2rDhg26cOGC06z9f//7X8f6nH9tNpuOHTumOnXqONr9/PPP+Y7x7Nmz2rhxo6ZOnarnn3/eUV+YUwgKI2cffvrpJ8esuJR9Ebtz58459vVa9e/fX4sXL5abm5sefPDBPOM5cuRIrvrLvffff/+97Ha70+f4z+fWqlVLkuTv768uXbpc837kuOOOO/TGG29ow4YN2r9/v8aPH+9Yd/vttys1NVWrVq3SL7/8on79+jnFs2HDBrVt2/ayP/LkpWbNmjp8+HCufS5If/unq/2g06hRIzVq1EiTJk3Sjh071LZtWy1atEjTpk0r9GsCAIoe59gDAEqlfx6C7ufnp9q1azvdDs3X11eSnG7FJmUfOp6VlaUFCxY41c+dO1cmk0k9evSQJIWHh0uSXn/9dad2r732Wr7jzJlV/ecs6rx58/K9jWvRs2fPy77enDlzJKnI7jXfsWNHvfjii1qwYIECAwPzjGf37t3auXOnoy45OVlvvfWWgoOD1aBBA0e7kydP6pNPPnG0S0lJ0VtvveW0vRYtWqhWrVqaNWuWkpKScr3emTNnCrU/OefMz5kzR1ar1WnGPjg4WFWrVnXcWu7S6wXcf//9ysrK0osvvphrm5mZmbn64qXCw8P1xx9/6Msvv3TUpaWl6f/+7/8KtQ/Slf8GEhMTlZmZ6VTXqFEjubm5XfGWggAA12HGHgBQKjVo0EBhYWFq0aKFypcvr7179+qTTz7RiBEjHG1atGghSRo1apTCw8Pl7u6uBx98UL1791bHjh317LPP6vjx42rSpInWr1+vL774QqNHj3bMArdo0UL9+vXTvHnz9Ndffzlud/fjjz9Kyt/h7f7+/mrfvr1mzJghq9Wqm266SevXr9exY8eK4V3JrUmTJoqIiNBbb72lc+fOqUOHDtq9e7eWLFmiu+++Wx07diyS13Fzc9OkSZOu2u5f//qXPvjgA/Xo0UOjRo1S+fLltWTJEh07dkyffvqp45Zxjz/+uBYsWKCBAwdq3759qlq1qt577z35+Pjket23335bPXr0UMOGDTVo0CDddNNN+uOPP7R582b5+/vrq6++KvD+1KhRQ0FBQdq5c6eCg4NVrVo1p/W33367Pv30U5lMJrVt29ZR36FDBz3xxBOaPn264uLi1K1bN5nNZv30009avny55s+f73RBwEs98cQTWrBggR566CE99dRTqlq1qpYuXeo4zL8wp1PUqlVLZcuW1aJFi1SmTBn5+vqqdevW+u677zRixAjdd999uuWWW5SZman33ntP7u7uTkcgAABKBhJ7AECpNGrUKH355Zdav3690tPTVbNmTU2bNs3pkOm+fftq5MiR+vDDD/X+++/LbrfrwQcflJubm7788ks9//zz+uijjxQVFaXg4GDNnDnTcbX4HO+++64CAwP1wQcfaMWKFerSpYs++ugj1a1b15FwXc2yZcs0cuRILVy4UHa7Xd26ddOaNWtyJYvF5e2339bNN9+s6OhorVixQoGBgZo4caImT558XV7/UlWqVNGOHTs0YcIEvfbaa0pLS1Pjxo311VdfOR094OPjo40bN2rkyJF67bXX5OPjowEDBqhHjx7q3r270zbDwsK0c+dOxxEDSUlJCgwMVOvWrfXEE08UOtY77rhDH3zwgdNsfY62bdvq008/Vb169VShQgWndYsWLVKLFi305ptv6t///rc8PDwUHByshx9+2OlHgH/y8/PTpk2bNHLkSM2fP19+fn4aOHCgbr/9dvXr1y/f/e1SZrNZS5Ys0cSJEzV06FBlZmYqKipKHTp0UHh4uL766iv98ccf8vHxUZMmTbRmzRrHHRsAACWHyZ7fK6gAAIB8iYuLU7NmzfT+++9rwIABrg4Hpdy8efM0ZswY/f7777rppptcHQ4AwAU4xx4AgGuQmpqaq27evHlyc3NT+/btXRARSrN/9re0tDS9+eabqlOnDkk9ANzAOBQfAIBrMGPGDO3bt08dO3aUh4eH1qxZozVr1mjIkCEKCgpydXgoZfr27asaNWqoadOmOn/+vN5//33997//veLt8wAANwYOxQcA4BrExMRo6tSpOnz4sJKSklSjRg098sgjevbZZ+Xhwe/nKFrz5s3T22+/rePHjysrK0sNGjTQM888owceeMDVoQEAXIjEHgAAAAAAA+McewAAAAAADIzEHgAAAAAAA+Pkv3yw2Ww6efKkypQpI5PJ5OpwAAAAAAClnN1u14ULF1StWjW5ueU9J09inw8nT57kysYAAAAAgOvut99+U/Xq1fNsQ2KfD2XKlJGU/Yb6+/u7OJrrw2q1av369erWrZvMZrOrw0FerFYpKiq7PGiQVMI/L/oWigt9C8WFvoXiQt9yHWuWVVH7s8dPg5oNktm9dL3/9K3SITExUUFBQY58NC8k9vmQc/i9v7//DZXY+/j4yN/fny+Dki45WRo/Prs8bJjk6+vaeK6CvoXiQt9CcaFvobjQt1wnOSNZ47dmj5+G3TFMvpaSPX4qKPpW6ZKf08G5eB4AAAAAAAZGYg8AAAAAgIGR2AMAAAAAYGCcYw8AAAAARchutyszM1NZWVkueX2r1SoPDw+lpaW5LAbkj9lslru7+zVvh8QeAAAAAIpIRkaG4uPjlZKS4rIY7Ha7AgMD9dtvv+XrwmtwHZPJpOrVq8vPz++atkNiDwAAAABFwGaz6dixY3J3d1e1atVksVhckljbbDYlJSXJz89Pbm6cfV1S2e12nTlzRr///rvq1KlzTTP3JPaA0Xl6SitXXiwDAAAgT54enlr50EpHuahkZGTIZrMpKChIPj4+RbbdgrLZbMrIyJCXlxeJfQlXqVIlHT9+XFarlcQeuKF5eEi9erk6CgAAAMPwcPNQr1uKb/xEMo38KqojOuhxAAAAAAAYGDP2gNFZrdLSpdnlAQMks9m18QAAAJRw1iyrlh7MHj8NaDRAZnfGTzA2ZuwBo8vIkAYNyl4yMlwdDQAAQImXkZWhQV8M0qAvBikji/ETis/x48dlMpkUFxdXrK9DYg8AAAAAN7jIyEjdfffdrg6jwCIjI2UymRxLhQoV1L17dx04cMDVoV1XJPYAAAAAgBItI48jU7t37674+HjFx8dr48aN8vDw0J133nkdo3M9EnsAAAAAKG7JyVde0tLy3zY1NX9ti9iWLVt02223ydPTU1WrVtW//vUvZWZmSpJWrlypsmXLKisrS5IUFxcnk8mkf/3rX47nP/bYY3r44Ycdj7dt26Z27drJ29tbQUFBGjVqlJIviTs4OFgvvviiBg4cKH9/fw0ZMuSKsXl6eiowMFCBgYFq2rSp/vWvf+m3337TmTNnHG0OHjyoTp06ydvbWxUqVNCQIUOUlJTkWB8WFqbRo0c7bffuu+9WZGSkU0wvv/yyHn30UZUpU0Y1atTQW2+95fSc3bt3q1mzZvLy8lLLli21f//+fLy7147EHgAAAACKm5/flZd+/ZzbVq585bY9eji3DQ7O1cbN379IQ//jjz/Us2dPtWrVSt99953eeOMNvfPOO5o2bZokqV27drpw4YIjid2yZYsqVqyo2NhYxza2bNmisLAwSdLRo0fVvXt39evXTwcOHNBHH32kbdu2acSIEU6vO2vWLDVp0kT79+/Xc889l69Yk5KS9P7776t27dqqUKGCJCk5OVnh4eEqV66c9uzZo+XLl2vDhg25Xi8/Zs+e7UjYn3zySQ0bNkxHjhxxvPadd96pBg0aaN++fZoyZYrGjRtX4NcoDK6KDwAAAAC4otdff11BQUFasGCBTCaT6tWrp5MnT2rChAl6/vnnFRAQoKZNmyo2NlYtW7ZUbGysxowZo6lTpyopKUnnz5/Xzz//rA4dOkiSpk+frgEDBjhmyOvUqaP//Oc/6tChg9544w15eXlJkjp16qSnn376qvGtXLlSfn5+krKT+KpVq2rlypVyc8uex162bJnS0tL07rvvytfXV5K0YMEC9e7dW6+++qqqVKmS7/eiZ8+eevLJJyVJEyZM0Ny5c7V582bVrVtXy5Ytk81m0zvvvCMvLy81bNhQv//+u4YNG5bv7RcWM/YAAAAAUNySkq68fPqpc9vTp6/cds0a57bHj+dqY0tMLNLQf/jhB4WGhspkMjnq2rZtq6SkJP3++++SpA4dOig2NlZ2u11bt25V3759Vb9+fW3btk1btmxRtWrVVKdOHUnSd999p+joaPn5+TmW8PBw2Ww2HTt2zPEaLVu2zFd8HTt2VFxcnOLi4rR7926Fh4erR48e+vXXXx3xN2nSxJHU58Rvs9kcs+351bhxY0fZZDIpMDBQp0+fdrxO48aNHT9MSFJoaGiBtl9YzNgDRufpKX388cUyAAAA8uTp4amP7/3YUb4uLkkqi72tzSYVcXJ/NWFhYVq8eLG+++47mc1m1atXT2FhYYqNjdXZs2cds/VS9iHrTzzxhEaNGpVrOzVq1HCUffP5Pvj6+qp27dqOx2+//bYCAgL0f//3f47TBa7Gzc1Ndrvdqc5qteZqZzabnR6bTCbZbLZ8vUZxIrEHjM7DQ7rvPldHAQAAYBgebh66ryHjp/yqX7++Pv30U9ntdses/fbt21WmTBlVr15d0sXz7OfOnetI4sPCwvTKK6/o7NmzTofUN2/eXIcPH3ZKxouSyWSSm5ubUv93ocH69esrOjpaycnJjh8Ltm/fLjc3N9WtW1eSVKlSJcXHxzu2kZWVpe+//14dO3bM9+vWr19f7733ntLS0hyz9rt27Sqq3coTh+IDAAD8T+/euZcHHshel/MvAJRW58+fdxzSnrP89ttvevLJJ/Xbb79p5MiR+u9//6svvvhCkydP1tixYx3nsZcrV06NGzfW0qVLHRfJa9++vb799lv9+OOPTjP2EyZM0I4dOzRixAjFxcXpp59+0hdffFGoi9lJUnp6uhISEpSQkKAffvhBI0eOVFJSknr37i1JGjBggLy8vBQREaHvv/9emzdv1siRI/XII484zq/v1KmTVq1apVWrVum///2vhg0bpnPnzhUojv79+8tkMunxxx/X4cOHtXr1as2aNatQ+1RQzNgDRpeZKa1YkV2+557sGXwAAABcUaYtUyt+yB4/3VP/Hnm4MX6SpNjYWDVr1sypbvDgwXr77be1evVqjR8/Xk2aNFH58uU1ePBgTZo0yalthw4dFBcX50jsy5cvrwYNGujUqVOOmXEp+zz1LVu26Nlnn1W7du1kt9tVq1YtPVDIX1DXrl2rqlWrSpLKlCmjevXqafny5Y44fHx8tG7dOj311FNq1aqVfHx81K9fP82ZM8exjUcffVTfffedBg4cKA8PD40ZM6ZAs/WS5Ofnp6+++kpDhw5Vs2bN1KBBA7366qvq98+7HhQDk/2fJxIgl8TERAUEBOj8+fPyL+JbR5RUVqtVq1evVs+ePXOdR4ISJjk5+9YmUvYFUwpyTpYL0LdQXOhbKAr/m9xxYjZbFRGxWkuW9NRnn9G3UHT43nKd5Ixk+U3PHj8lTUySr6Voxk9paWk6duyYQkJCnC6gdr3ZbDYlJibK39/fMaOOkimvPlOQPJRPGQAAAAAAAyOxBwAAAADAwEjsAQAAAAAwMBJ7AAAAAAAMjMQeAAAAAAADI7EHAAAAAMDAuGEjYHQWixQVdbEMAACAPFncLYrqE+UoA0ZHYg8YndksRUa6OgoAAADDMLubFdk00tVhAEWGQ/EBAAAAADAwEnvA6DIzpVWrspfMTFdHAwAAUOJl2jK16sdVWvXjKmXaGD+heEVGRuruu+8u1tcgsQeMLj1duvPO7CU93dXRAAAAlHjpmem684M7decHdyo9k/GTJIWFhWn06NG56qOjo1W2bNnrHk9+HT9+XCaTybFYLBbVrl1b06ZNk91ud3V41w3n2AMAAAAASrSsrCyZTCa5uV1+bnrDhg1q2LCh0tPTtW3bNj322GOqWrWqBg8efJ0jdQ1m7AEAAACgmCVnJF9xSctMy3fbVGtqvtoWl5zDyqdOnapKlSrJ399fQ4cOVUZGhqNNWFiYRowYoREjRiggIEAVK1bUc8895zSDnp6ernHjxummm26Sr6+vWrdurdjYWMf6nCMFvvzySzVo0ECenp46ceLEFeOqUKGCAgMDVbNmTQ0YMEBt27bVt99+61hvs9n0wgsvqHr16vL09FTTpk21du1ax/rY2FiZTCadO3fOURcXFyeTyaTjx487xbRu3TrVr19ffn5+6t69u+Lj4x3PycrK0tixY1W2bFlVqFBBzzzzzHU5coAZewAAAAAoZn7T/a64rmednlrVf5XjceVZlZViTbls2w41Oyg2MtbxOHh+sP5M+TNXu7NPnS18sFexceNGeXl5KTY2VsePH9egQYNUoUIFvfTSS442S5Ys0eDBg7V7927t3btXQ4YMUY0aNfT4449LkkaMGKHDhw/rww8/VLVq1bRixQp1795dBw8eVJ06dSRJKSkpevXVV/X222+rQoUKqly5cr7i27t3r/bt26eBAwc66ubPn6/Zs2frzTffVLNmzbR48WLdddddOnTokOP18iMlJUWzZs3Se++9Jzc3Nz388MMaN26cli5dKkmaPXu2oqOjtXjxYtWvX1+zZ8/WihUr1KlTp3y/RmEwYw8AAAAAyDeLxaLFixerYcOG6tWrl1544QX95z//kc1mc7QJCgrS3LlzVbduXQ0YMEAjR47U3LlzJUknTpxQVFSUli9frnbt2qlWrVoaN26c7rjjDkVFRTm2YbVa9frrr+v2229X3bp15ePjc8WYbr/9dvn5+clisahVq1a6//77nRL7WbNmacKECXrwwQdVt25dvfrqq2ratKnmzZtXoH23Wq1atGiRWrZsqebNm2vEiBHauHGjY/28efM0ceJE9e3bV/Xr19eiRYsUEBBQoNcoDGbsAQAAAKCYJU1MuuI6dzd3p8enx52+Yls3k/Pc7PGnjudqY7PZlJWWVbAAC6BJkyZOSXZoaKiSkpL022+/qWbNmpKkNm3ayGQyObWZPXu2srKydPDgQWVlZemWW25x2m56eroqVKjgeGyxWNS4ceN8xfTRRx+pfv36slqt+v777zVy5EiVK1dOr7zyihITE3Xy5Em1bdvW6Tlt27bVd999V6B99/HxUa1atRyPq1atqtOnsz+v8+fPKz4+Xq1bt3as9/DwUMuWLYv9cHwSewAAAAAoZr4W3+vW1mazKTEtMd/bkCR/f3+dP38+V/25c+eKfMY5KSlJ7u7u2rdvn9zdnX/U8PO7eMqCt7e3048DeQkKClLt2rUlSfXr19fRo0f13HPPacqUKfl6fs5F+S5NwK1Wa652ZrPZ6bHJZCoRV98nsQeMzmKRFiy4WAYAAECeLO4WLeixwFGGVLduXa1fvz5X/bfffptrZv27775TamqqvL29JUm7du2Sn5+fgoKCHG2++eYbp+fs2rVLderUkbu7u5o1a6asrCydPn1a7dq1K4a9kdzd3ZWZmamMjAz5+/urWrVq2r59uzp06OBos337dt12222SpEqVKkmS4uPjVa5cOUnZF88riICAAFWtWlXffPON2rdvL0nKzMzUvn371Lx58yLYqysjsQeMzmyWhg93dRQAAACGYXY3a/htjJ8uNWzYMC1YsECjRo3SY489Jk9PT61atUoffPCBvvrqK6e2GRkZGjx4sCZNmqTjx49r8uTJGjFihNOt6E6cOKGxY8fqiSee0LfffqvXXntNs2fPliTdcsstGjBggAYOHKjZs2erWbNmOnPmjDZu3KjGjRurV69eBY7/r7/+UkJCgjIzM3Xw4EHNnz9fHTt2lL+/vyRp/Pjxmjx5smrVqqWmTZsqKipKcXFxjove1a5dW0FBQZoyZYpeeukl/fjjj454C+Kpp57SK6+8ojp16qhevXqaM2eO05X2iwuJPQAAAADc4G6++WZ9/fXXevbZZ9WlSxdlZGSoXr16Wr58ubp37+7UtnPnzqpTp47at2+v9PR0PfTQQ7kOeR84cKBSU1N12223yd3dXU899ZSGDBniWB8VFaVp06bp6aef1h9//KGKFSuqTZs2uvPOOwsVf5cuXSRlz9RXrVpVPXv2dLpK/6hRo3T+/Hk9/fTTOn36tBo0aKAvv/zScUV8s9msDz74QMOGDVPjxo3VqlUrTZs2Tffdd1+B4nj66acVHx+viIgIubm56dFHH9U999xz2dMcipLJXhJOCCjhEhMTFRAQoPPnzzt+8SntrFarVq9erZ49e+Y6jwQlTFaWtHVrdrldO+kf5ymVNPQtFBf6FopC796568xmqyIiVmvJkp767DP6FooO31uuk2XL0tYT2eOndjXa5bp4XWGlpaXp2LFjCgkJkZeXV5FsszBsNpsSExPl7+/vNIteFCIjI3Xu3Dl9/vnnV2wTFhZWqCvO34jy6jMFyUOZsQeMLi1N6tgxu5yUJPnm/2IrAAAAN6K0zDR1XJI9fkqamFSgi9UBJRH3sQcAAAAAwMCYsQcAAAAA5Et0dPRV28TGxhZ7HHDm0hn7N954Q40bN5a/v7/8/f0VGhqqNWvWONaHhYXJZDI5LUOHDnXaxokTJ9SrVy/5+PiocuXKGj9+vDIzM53axMbGqnnz5vL09FTt2rXz1RkBAAAAADACl87YV69e3XErALvdriVLlqhPnz7av3+/GjZsKEl6/PHH9cILLzie4+Pj4yhnZWWpV69eCgwM1I4dOxQfH6+BAwfKbDbr5ZdfliQdO3ZMvXr10tChQ7V06VJt3LhRjz32mKpWrarw8PDru8MAAAAASj2uT478Kqq+4tLEvvc/Lj370ksv6Y033tCuXbscib2Pj48CAwMv+/z169fr8OHD2rBhg6pUqaKmTZvqxRdf1IQJEzRlyhRZLBYtWrRIISEhjnsQ1q9fX9u2bdPcuXNJ7AEAAAAUmZy7G6SkpMjb29vF0cAIMjIyJGXfpu9alJhz7LOysrR8+XIlJycrNDTUUb906VK9//77CgwMVO/evfXcc885Zu137typRo0aqUqVKo724eHhGjZsmA4dOqRmzZpp586djnsaXtpm9OjRV4wlPT1d6enpjseJiYmSsm9JYrVai2J3S7yc/bxR9tfQrFaZHUWrVMI/M/oWigt9C0XhcnccM5utjn/pXihKfG+5zqXvudVqldVUdJ9BmTJldOrUKdlsNvn4+MhkMhXZtvPLbrcrIyNDqampLnl95I/NZtPp06fl5eUlu92e67ugIN8NLk/sDx48qNDQUKWlpcnPz08rVqxQgwYNJEn9+/dXzZo1Va1aNR04cEATJkzQkSNH9Nlnn0mSEhISnJJ6SY7HCQkJebZJTExUamrqZX9Jmz59uqZOnZqrfv369U6nAtwIYmJiXB0CrsJktapWRIQk6eiGDbIb5D649C0UF/oWrsX/vk4vq3//GK1eff1iwY2D763rz2qzKqJa9h/8hvUbZHYr2vFTmTJllJycXOT3kEfpY7VadebMGR04cCDXupSUlHxvx+WJfd26dRUXF6fz58/rk08+UUREhLZs2aIGDRpoyJAhjnaNGjVS1apV1blzZx09elS1atUqtpgmTpyosWPHOh4nJiYqKChI3bp1k7+/f7G9bklitVoVExOjrl27Og4pQgnWp48k6RYXh5Ef9C0UF/oWisIDD+SuM5ut6t8/RsuWddX779O3UHT43nKtPupTrNvPyspSZmamS863z8zM1I4dO3T77bfLw8PlKR+uwGQyyWw2X/EHoJwjx/PD5Z+yxWJR7dq1JUktWrTQnj17NH/+fL355pu52rZu3VqS9PPPP6tWrVoKDAzU7t27ndqcOnVKkhzn5QcGBjrqLm3j7+9/xfNePD095enpmavebDbfcF+6N+I+4/qgb6G40LdwLfI66tFqpW+hePC9VTq58jO1Wq3KzMyUn58ffcvACvLZlbhjQ2w2m9P57ZeKi4uTJFWtWlWSFBoaqoMHD+r06dOONjExMfL393cczh8aGqqNGzc6bScmJsbpPH7A0LKypD17spesLFdHAwAAUOJl2bK054892vPHHmXZGD/B+Fw6Yz9x4kT16NFDNWrU0IULF7Rs2TLFxsZq3bp1Onr0qJYtW6aePXuqQoUKOnDggMaMGaP27durcePGkqRu3bqpQYMGeuSRRzRjxgwlJCRo0qRJGj58uGPGfejQoVqwYIGeeeYZPfroo9q0aZM+/vhjrVq1ypW7DhSdtDTpttuyy0lJkq+va+MBAAAo4dIy03Tb29njp6SJSfK1MH6Csbk0sT99+rQGDhyo+Ph4BQQEqHHjxlq3bp26du2q3377TRs2bNC8efOUnJysoKAg9evXT5MmTXI8393dXStXrtSwYcMUGhoqX19fRUREON33PiQkRKtWrdKYMWM0f/58Va9eXW+//Ta3ugMAAAAAlAouTezfeeedK64LCgrSli1brrqNmjVravVVLlEbFham/fv3Fzg+AAAAAABKuhJ3jj0AAAAAAMg/EnsAAAAAAAyMxB4AAAAAAAMjsQcAAAAAwMBcevE8AEXAbJYmT75YBgAAQJ7M7mZN7jDZUQaMjsQeMDqLRZoyxdVRAAAAGIbF3aIpYVNcHQZQZDgUHwAAAAAAA2PGHjA6m0364Yfscv36khu/1wEAAOTFZrfphzPZ46f6lerLzcT4CcZGYg8YXWqqdOut2eWkJMnX17XxAAAAlHCp1lTd+kb2+ClpYpJ8LYyfYGz8NAUAAAAAgIGR2AMAAAAAYGAk9gAAAAAAGBiJPQAAAAAABkZiDwAAAACAgZHYAwAAAABgYNzuDjA6s1kaN+5iGQAAAHkyu5s1LnScowwYHYk9YHQWizRzpqujAAAAMAyLu0UzuzF+QunBofgAAAAAABgYM/aA0dls0okT2eUaNSQ3fq8DAADIi81u04nz2eOnGgE15GZi/ARjI7EHjC41VQoJyS4nJUm+vq6NBwAAoIRLtaYqZH72+ClpYpJ8LYyfYGz8NAUAAAAAgIGR2AMAAAAAYGAk9gAAAAAAGBiJPQAAAAAABkZiDwAAAACAgZHYAwAAAABgYNzuDjA6Dw/pyScvlgEAAJAnDzcPPdnySUcZMDp6MWB0np7SwoWujgIAAMAwPD08tbAX4yeUHhyKDwAAAACAgTFjDxid3S79+Wd2uWJFyWRybTwAAAAlnN1u158p2eOnij4VZWL8BIMjsQeMLiVFqlw5u5yUJPn6ujYeAACAEi7FmqLKs7LHT0kTk+RrYfwEY+NQfAAAAAAADIzEHgAAAAAAAyOxBwAAAADAwEjsAQAAAAAwMBJ7AAAAAAAMjMQeAAAAAAAD43Z3gNF5eEgRERfLAAAAyJOHm4cimkQ4yoDR0YsBo/P0lKKjXR0FAACAYXh6eCr67mhXhwEUGQ7FBwAAAADAwJixB4zObpdSUrLLPj6SyeTaeAAAAEo4u92uFGv2+MnH7CMT4ycYHDP2gNGlpEh+ftlLToIPAACAK0qxpshvup/8pvs5EnzAyEjsAQAAAAAwMBJ7AAAAAAAMjMQeAAAAAAADI7EHAAAAAMDASOwBAAAAADAwlyb2b7zxhho3bix/f3/5+/srNDRUa9ascaxPS0vT8OHDVaFCBfn5+alfv346deqU0zZOnDihXr16ycfHR5UrV9b48eOVmZnp1CY2NlbNmzeXp6enateurejo6OuxewAAAAAAFDuX3se+evXqeuWVV1SnTh3Z7XYtWbJEffr00f79+9WwYUONGTNGq1at0vLlyxUQEKARI0aob9++2r59uyQpKytLvXr1UmBgoHbs2KH4+HgNHDhQZrNZL7/8siTp2LFj6tWrl4YOHaqlS5dq48aNeuyxx1S1alWFh4e7cveBouHuLt1778UyAAAA8uTu5q57G9zrKANG59LEvnfv3k6PX3rpJb3xxhvatWuXqlevrnfeeUfLli1Tp06dJElRUVGqX7++du3apTZt2mj9+vU6fPiwNmzYoCpVqqhp06Z68cUXNWHCBE2ZMkUWi0WLFi1SSEiIZs+eLUmqX7++tm3bprlz55LYo3Tw8pKWL3d1FAAAAIbh5eGl5fcxfkLp4dLE/lJZWVlavny5kpOTFRoaqn379slqtapLly6ONvXq1VONGjW0c+dOtWnTRjt37lSjRo1UpUoVR5vw8HANGzZMhw4dUrNmzbRz506nbeS0GT169BVjSU9PV3p6uuNxYmKiJMlqtcpqtRbRHpdsOft5o+wvrh/6FooLfQtFwWy+XJ3V8S/dC0WJ7y0UF/pW6VCQz8/lif3BgwcVGhqqtLQ0+fn5acWKFWrQoIHi4uJksVhUtmxZp/ZVqlRRQkKCJCkhIcEpqc9Zn7MurzaJiYlKTU2Vt7d3rpimT5+uqVOn5qpfv369fHx8Cr2vRhQTE+PqEFBK0bdQXOhbuBYREVde179/jFavvn6x4MbB9xaKC33L2FJSUvLd1uWJfd26dRUXF6fz58/rk08+UUREhLZs2eLSmCZOnKixY8c6HicmJiooKEjdunWTv7+/CyO7fqxWq2JiYtS1a1eZLzd9gZIjOVnmcuUkSdazZyVfXxcHlDf6FooLfQtF4YEHcteZzVb17x+jZcu66v336VsoOnxvuU5yRrLKzcoeP50dd1a+lpI9fioo+lbpkHPkeH64PLG3WCyqXbu2JKlFixbas2eP5s+frwceeEAZGRk6d+6c06z9qVOnFBgYKEkKDAzU7t27nbaXc9X8S9v880r6p06dkr+//2Vn6yXJ09NTnp6euerNZvMN94dxI+6z4Vzy+ZjN5ssfR1oC0bdQXOhbuBZ5HfVotdK3UDz43rr+zHbn8VNpff9L877dCAry2ZW4+9jbbDalp6erRYsWMpvN2rhxo2PdkSNHdOLECYWGhkqSQkNDdfDgQZ0+fdrRJiYmRv7+/mrQoIGjzaXbyGmTsw0AAAAAAIzMpTP2EydOVI8ePVSjRg1duHBBy5YtU2xsrNatW6eAgAANHjxYY8eOVfny5eXv76+RI0cqNDRUbdq0kSR169ZNDRo00COPPKIZM2YoISFBkyZN0vDhwx0z7kOHDtWCBQv0zDPP6NFHH9WmTZv08ccfa9WqVa7cdQAAAAAAioRLE/vTp09r4MCBio+PV0BAgBo3bqx169apa9eukqS5c+fKzc1N/fr1U3p6usLDw/X66687nu/u7q6VK1dq2LBhCg0Nla+vryIiIvTCCy842oSEhGjVqlUaM2aM5s+fr+rVq+vtt9/mVncAAAAAgFLBpYn9O++8k+d6Ly8vLVy4UAsXLrxim5o1a2r1VS5RGxYWpv379xcqRgAAAAAASrISd449AAAAAADIP5dfFR/ANXJ3l3r2vFgGAABAntzd3NWzTk9HGTA6EnvA6Ly8JC4GCQAAkG9eHl5a1Z/xE0oPDsUHAAAAAMDASOwBAAAAADAwEnvA6JKTJV/f7CU52dXRAAAAlHjJGcnyfdlXvi/7KjmD8ROMj3PsgdIgJcXVEQAAABhKipXxE0oPZuwBAAAAADAwEnsAAAAAAAyMxB4AAAAAAAMjsQcAAAAAwMBI7AEAAAAAMDCuig8YnZub1KHDxTIAAADy5GZyU4eaHRxlwOhI7AGj8/aWYmNdHQUAAIBheJu9FRsZ6+owgCLDz1MAAAAAABgYiT0AAAAAAAZGYg8YXXKyVKlS9pKc7OpoAAAASrzkjGRVmllJlWZWUnIG4ycYH+fYA6XBn3+6OgIAAABD+TOF8RNKD2bsAQAAAAAwMBJ7AAAAAAAMjMQeAAAAAAADI7EHAAAAAMDASOwBAAAAADAwrooPGJ2bm9Sy5cUyAAAA8uRmclPLai0dZcDoSOwBo/P2lvbscXUUAAAAhuFt9taexxk/ofTg5ykAAAAAAAyMxB4AAAAAAAMjsQeMLiVFCg7OXlJSXB0NAABAiZdiTVHwvGAFzwtWipXxE4yPc+wBo7PbpV9/vVgGAABAnux2u349/6ujDBgdM/YAAAAAABgYiT0AAAAAAAZGYg8AAAAAgIGR2AMAAAAAYGAk9gAAAAAAGBhXxQeMzmSSGjS4WAYAAECeTCaTGlRq4CgDRkdiDxidj4906JCrowAAADAMH7OPDj3J+AmlB4fiAwAAAABgYCT2AAAAAAAYGIk9YHQpKVLDhtlLSoqrowEAACjxUqwpavh6QzV8vaFSrIyfYHycYw8Ynd0uHT58sQwAAIA82e12HT5z2FEGjI4ZewAAAAAADIzEHgAAAAAAAyOxBwAAAADAwEjsAQAAAAAwMBJ7AAAAAAAMjKviA0ZnMkk1a14sAwAAIE8mk0k1A2o6yoDRkdgDRufjIx0/7uooAAAADMPH7KPjo4+7OgygyHAoPgAAAAAABubSxH769Olq1aqVypQpo8qVK+vuu+/WkSNHnNqEhYXJZDI5LUOHDnVqc+LECfXq1Us+Pj6qXLmyxo8fr8zMTKc2sbGxat68uTw9PVW7dm1FR0cX9+4BAAAAAFDsXJrYb9myRcOHD9euXbsUExMjq9Wqbt26KTk52and448/rvj4eMcyY8YMx7qsrCz16tVLGRkZ2rFjh5YsWaLo6Gg9//zzjjbHjh1Tr1691LFjR8XFxWn06NF67LHHtG7duuu2r0CxSU2VWrXKXlJTXR0NAABAiZdqTVWr/2ulVv/XSqlWxk8wPpeeY7927Vqnx9HR0apcubL27dun9u3bO+p9fHwUGBh42W2sX79ehw8f1oYNG1SlShU1bdpUL774oiZMmKApU6bIYrFo0aJFCgkJ0ezZsyVJ9evX17Zt2zR37lyFh4cX3w4C14PNJu3de7EMAACAPNnsNu09uddRBoyuRF087/z585Kk8uXLO9UvXbpU77//vgIDA9W7d28999xz8vHxkSTt3LlTjRo1UpUqVRztw8PDNWzYMB06dEjNmjXTzp071aVLF6dthoeHa/To0ZeNIz09Xenp6Y7HiYmJkiSr1Sqr1XrN+2kEOft5o+yvoVmtMjuKVqmEf2b0LRQX+haKgtl8uTqr41+6F4oS31uuc+l7brVaZTWVrs+AvlU6FOTzKzGJvc1m0+jRo9W2bVvdeuutjvr+/furZs2aqlatmg4cOKAJEyboyJEj+uyzzyRJCQkJTkm9JMfjhISEPNskJiYqNTVV3t7eTuumT5+uqVOn5opx/fr1jh8UbhQxMTGuDgFX4Z6Wpjv/V163bp2yvLxcGk9+0bdQXOhbuBYREVde179/jFavvn6x4MbB99b1l5aV5iivW7dOXu7GGD8VFH3L2FJSUvLdtsQk9sOHD9f333+vbdu2OdUPGTLEUW7UqJGqVq2qzp076+jRo6pVq1axxDJx4kSNHTvW8TgxMVFBQUHq1q2b/P39i+U1Sxqr1aqYmBh17dpV5stNX6DkuOSaFOHh4ZKvrwuDuTr6FooLfQtF4YEHcteZzVb17x+jZcu66v336VsoOnxvuU5yRrJ0MLscHh4uX0vJHj8VFH2rdMg5cjw/SkRiP2LECK1cuVJff/21qlevnmfb1q1bS5J+/vln1apVS4GBgdq9e7dTm1OnTkmS47z8wMBAR92lbfz9/XPN1kuSp6enPD09c9WbzeYb7g/jRtxnw7nk8zGbzZc/jrQEom+huNC3cC3yOurRaqVvoXjwvXX9me3O46fS+v6X5n27ERTks3PpVfHtdrtGjBihFStWaNOmTQoJCbnqc+Li4iRJVatWlSSFhobq4MGDOn36tKNNTEyM/P391aBBA0ebjRs3Om0nJiZGoaGhRbQnAAAAAAC4hktn7IcPH65ly5bpiy++UJkyZRznxAcEBMjb21tHjx7VsmXL1LNnT1WoUEEHDhzQmDFj1L59ezVu3FiS1K1bNzVo0ECPPPKIZsyYoYSEBE2aNEnDhw93zLoPHTpUCxYs0DPPPKNHH31UmzZt0scff6xVq1a5bN+BIlWxoqsjAAAAMJSKPoyfUHq4NLF/4403JElhYWFO9VFRUYqMjJTFYtGGDRs0b948JScnKygoSP369dOkSZMcbd3d3bVy5UoNGzZMoaGh8vX1VUREhF544QVHm5CQEK1atUpjxozR/PnzVb16db399tvc6g6lg6+vdOaMq6MAAAAwDF+Lr86MZ/yE0sOlib3dbs9zfVBQkLZs2XLV7dSsWVOrr3KZ2rCwMO3fv79A8QEAAAAAUNK59Bx7AAAAAABwbUjsAaNLTZXCwrKX1FRXRwMAAFDipVpTFRYdprDoMKVaGT/B+ErE7e4AXAObTco5ZcVmc20sAAAABmCz27Tl1y2OMmB0zNgDAAAAAGBgJPYAAAAAABgYiT0AAAAAAAZGYg8AAAAAgIGR2AMAAAAAYGBcFR8oDXx8XB0BAACAofiYGT+h9CCxB4zO11dKTnZ1FAAAAIbha/FV8r8ZP6H04FB8AAAAAAAMjMQeAAAAAAADI7EHjC4tTerVK3tJS3N1NAAAACVeWmaaei3rpV7Leiktk/ETjI9z7AGjy8qSVq++WAYAAECesmxZWv3TakcZMDpm7AEAAAAAMDASewAAAAAADIzEHgAAAAAAAyOxBwAAAADAwEjsAQAAAAAwMBJ7AAAAAAAMjNvdAUbn6yvZ7a6OAgAAwDB8Lb6yT2b8hNKjUDP2v/zyS1HHAQAAAAAACqFQiX3t2rXVsWNHvf/++0pLSyvqmAAAAAAAQD4VKrH/9ttv1bhxY40dO1aBgYF64okntHv37qKODUB+pKVJ992XvfBDGwAAwFWlZabpvuX36b7l9yktk/ETjK9QiX3Tpk01f/58nTx5UosXL1Z8fLzuuOMO3XrrrZozZ47OnDlT1HECuJKsLOmTT7KXrCxXRwMAAFDiZdmy9MnhT/TJ4U+UZWP8BOO7pqvie3h4qG/fvlq+fLleffVV/fzzzxo3bpyCgoI0cOBAxcfHF1WcAAAAAADgMq4psd+7d6+efPJJVa1aVXPmzNG4ceN09OhRxcTE6OTJk+rTp09RxQkAAAAAAC6jULe7mzNnjqKionTkyBH17NlT7777rnr27Ck3t+zfCUJCQhQdHa3g4OCijBUAAAAAAPxDoRL7N954Q48++qgiIyNVtWrVy7apXLmy3nnnnWsKDgAAAAAA5K1Qif1PP/101TYWi0URERGF2TwAAAAAAMinQp1jHxUVpeXLl+eqX758uZYsWXLNQQEAAAAAgPwpVGI/ffp0VaxYMVd95cqV9fLLL19zUAAKwMdHSkrKXnx8XB0NAABAiedj9lHSxCQlTUySj5nxE4yvUIfinzhxQiEhIbnqa9asqRMnTlxzUAAKwGSSfH1dHQUAAIBhmEwm+VoYP6H0KNSMfeXKlXXgwIFc9d99950qVKhwzUEBAAAAAID8KVRi/9BDD2nUqFHavHmzsrKylJWVpU2bNumpp57Sgw8+WNQxAshLeroUGZm9pKe7OhoAAIASLz0zXZGfRyry80ilZzJ+gvEV6lD8F198UcePH1fnzp3l4ZG9CZvNpoEDB3KOPXC9ZWZKORetXLhQ8vR0bTwAAAAlXKYtU0u+yx4/Ley5UJ5i/ARjK1Rib7FY9NFHH+nFF1/Ud999J29vbzVq1Eg1a9Ys6vgAAAAAAEAeCpXY57jlllt0yy23FFUsAAAAAACggAqV2GdlZSk6OlobN27U6dOnZbPZnNZv2rSpSIIDAAAAAAB5K1Ri/9RTTyk6Olq9evXSrbfeKpPJVNRxAQAAAACAfChUYv/hhx/q448/Vs+ePYs6HgAAAAAAUACFut2dxWJR7dq1izoWAAAAAABQQIVK7J9++mnNnz9fdru9qOMBUFA+PtLp09mLj4+rowEAACjxfMw+Oj3utE6POy0fM+MnGF+hDsXftm2bNm/erDVr1qhhw4Yym81O6z/77LMiCQ5APphMUqVKro4CAADAMEwmkyr5Mn5C6VGoxL5s2bK65557ijoWAAAAAABQQIVK7KOiooo6DgCFlZ4ujR2bXZ4zR/L0dG08AAAAJVx6ZrrGrsseP80JnyNPD8ZPMLZCnWMvSZmZmdqwYYPefPNNXbhwQZJ08uRJJSUlFVlwAPIhM1N6/fXsJTPT1dEAAACUeJm2TL2+93W9vvd1ZdoYP8H4CpXY//rrr2rUqJH69Omj4cOH68yZM5KkV199VePGjcv3dqZPn65WrVqpTJkyqly5su6++24dOXLEqU1aWpqGDx+uChUqyM/PT/369dOpU6ec2pw4cUK9evWSj4+PKleurPHjxyvzHwlObGysmjdvLk9PT9WuXVvR0dGF2XUAAAAAAEqUQiX2Tz31lFq2bKmzZ8/K29vbUX/PPfdo48aN+d7Oli1bNHz4cO3atUsxMTGyWq3q1q2bkpOTHW3GjBmjr776SsuXL9eWLVt08uRJ9e3b17E+KytLvXr1UkZGhnbs2KElS5YoOjpazz//vKPNsWPH1KtXL3Xs2FFxcXEaPXq0HnvsMa1bt64wuw8AAAAAQIlRqHPst27dqh07dshisTjVBwcH648//sj3dtauXev0ODo6WpUrV9a+ffvUvn17nT9/Xu+8846WLVumTp06Sco+v79+/fratWuX2rRpo/Xr1+vw4cPasGGDqlSpoqZNm+rFF1/UhAkTNGXKFFksFi1atEghISGaPXu2JKl+/fratm2b5s6dq/Dw8MK8BQAAAAAAlAiFSuxtNpuysrJy1f/+++8qU6ZMoYM5f/68JKl8+fKSpH379slqtapLly6ONvXq1VONGjW0c+dOtWnTRjt37lSjRo1UpUoVR5vw8HANGzZMhw4dUrNmzbRz506nbeS0GT169GXjSE9PV3p6uuNxYmKiJMlqtcpqtRZ6/4wkZz9vlP01NKtVZkfRKpXwz4y+heJC30JR+McdfP9XZ3X8S/dCUeJ7y3Uufc+tVqusptL1GdC3SoeCfH6FSuy7deumefPm6a233pKUfR/IpKQkTZ48WT179izMJmWz2TR69Gi1bdtWt956qyQpISFBFotFZcuWdWpbpUoVJSQkONpcmtTnrM9Zl1ebxMREpaamOp1OIGWf+z916tRcMa5fv14+Pj6F2j+jiomJcXUIuAr3tDTd+b/yunXrlOXl5dJ48ou+heJC38K1iIi48rr+/WO0evX1iwU3Dr63rr+0rDRHed26dfJyN8b4qaDoW8aWkpKS77aFSuxnz56t8PBwNWjQQGlpaerfv79++uknVaxYUR988EFhNqnhw4fr+++/17Zt2wr1/KI0ceJEjc25fZiyZ+yDgoLUrVs3+fv7uzCy68dqtSomJkZdu3aV+XLTFyg5LrkmRXh4uOTr68Jgro6+heJC30JReOCB3HVms1X9+8do2bKuev99+haKDt9brpOckSwdzC6Hh4fL11Kyx08FRd8qHXKOHM+PQiX21atX13fffacPP/xQBw4cUFJSkgYPHqwBAwbkmv3OjxEjRmjlypX6+uuvVb16dUd9YGCgMjIydO7cOadZ+1OnTikwMNDRZvfu3U7by7lq/qVt/nkl/VOnTsnf3/+y8Xp6esrzMvcCN5vNN9wfxo24z4bj7y8dOyZJMvv7S26FvovldUXfQnGhb+Fa5HXUo9VK30Lx4Hvr+vP38Nexp7LHT/4+/nIzGWP8VFD0LWMryGdXqMRekjw8PPTwww8X9umSJLvdrpEjR2rFihWKjY1VSEiI0/oWLVrIbDZr48aN6tevnyTpyJEjOnHihEJDQyVJoaGheumll3T69GlVrlxZUvYhJ/7+/mrQoIGjzep/HDsXExPj2AZgaG5uUnCwq6MAAAAwDDeTm4LLBrs6DKDIFCqxf/fdd/NcP3DgwHxtZ/jw4Vq2bJm++OILlSlTxnFOfEBAgLy9vRUQEKDBgwdr7NixKl++vPz9/TVy5EiFhoaqTZs2krLP92/QoIEeeeQRzZgxQwkJCZo0aZKGDx/umHUfOnSoFixYoGeeeUaPPvqoNm3apI8//lirVq0qzO4DAAAAAFBiFCqxf+qpp5weW61WpaSkyGKxyMfHJ9+J/RtvvCFJCgsLc6qPiopSZGSkJGnu3Llyc3NTv379lJ6ervDwcL3++uuOtu7u7lq5cqWGDRum0NBQ+fr6KiIiQi+88IKjTUhIiFatWqUxY8Zo/vz5ql69ut5++21udYfSISNDevbZ7PJLL0n/uA0lAAAAnGVkZejZjdnjp5c6vySLO+MnGFuhEvuzZ8/mqvvpp580bNgwjR8/Pt/bsdvtV23j5eWlhQsXauHChVdsU7NmzVyH2v9TWFiY9u/fn+/YAMOwWqVZs7LLU6aQ2AMAAFyFNcuqWTuzx09TwqaQ2MPwiuwqEXXq1NErr7ySazYfAAAAAAAUnyK9/KOHh4dOnjxZlJsEAAAAAAB5KNSh+F9++aXTY7vdrvj4eC1YsEBt27YtksAAAAAAAMDVFSqxv/vuu50em0wmVapUSZ06ddLs2bOLIi4AAAAAAJAPhUrsbTZbUccBAAAAAAAKoUjPsQcAAAAAANdXoWbsx44dm++2c+bMKcxLAMgvb2/p++8vlgEAAJAnb7O3vh/2vaMMGF2hEvv9+/dr//79slqtqlu3riTpxx9/lLu7u5o3b+5oZzKZiiZKAFfm5iY1bOjqKAAAAAzDzeSmhpUZP6H0KFRi37t3b5UpU0ZLlixRuXLlJElnz57VoEGD1K5dOz399NNFGiQAAAAAALi8Qp1jP3v2bE2fPt2R1EtSuXLlNG3aNK6KD1xvGRnSlCnZS0aGq6MBAAAo8TKyMjQldoqmxE5RRhbjJxhfoWbsExMTdebMmVz1Z86c0YULF645KAAFYLVKU6dml8ePlywW18YDAABQwlmzrJq6JXv8NP728bK4M36CsRVqxv6ee+7RoEGD9Nlnn+n333/X77//rk8//VSDBw9W3759izpGAAAAAABwBYWasV+0aJHGjRun/v37y2q1Zm/Iw0ODBw/WzJkzizRAAAAAAABwZYVK7H18fPT6669r5syZOnr0qCSpVq1a8vX1LdLgAAAAAABA3gp1KH6O+Ph4xcfHq06dOvL19ZXdbi+quAAAAAAAQD4UKrH/66+/1LlzZ91yyy3q2bOn4uPjJUmDBw/mVncAAAAAAFxHhUrsx4wZI7PZrBMnTsjHx8dR/8ADD2jt2rVFFhwAAAAAAMhboc6xX79+vdatW6fq1as71depU0e//vprkQQGIJ+8vKTduy+WAQAAkCcvDy/tfmy3owwYXaES++TkZKeZ+hx///23PD09rzkoAAXg7i61auXqKAAAAAzD3c1drW5i/ITSo1CH4rdr107vvvuu47HJZJLNZtOMGTPUsWPHIgsOAAAAAADkrVAz9jNmzFDnzp21d+9eZWRk6JlnntGhQ4f0999/a/v27UUdI4C8ZGRI8+dnl596SrJYXBsPAABACZeRlaH5u7LHT0+1eUoWd8ZPMLZCzdjfeuut+vHHH3XHHXeoT58+Sk5OVt++fbV//37VqlWrqGMEkBerVXrmmezFanV1NAAAACWeNcuqZzY8o2c2PCNrFuMnGF+BZ+ytVqu6d++uRYsW6dlnny2OmAAAAAAAQD4VeMbebDbrwIEDxRELAAAAAAAooEIdiv/www/rnXfeKepYAAAAAABAARXq4nmZmZlavHixNmzYoBYtWsjX19dp/Zw5c4okOAAAAAAAkLcCJfa//PKLgoOD9f3336t58+aSpB9//NGpjclkKrroAAAAAABAngqU2NepU0fx8fHavHmzJOmBBx7Qf/7zH1WpUqVYggMAAAAAAHkrUGJvt9udHq9Zs0bJyclFGhCAAvLykv73Y5u8vFwbCwAAgAF4eXhpc8RmRxkwukKdY5/jn4k+ABdwd5fCwlwdBQAAgGG4u7krLDjM1WEARaZAV8U3mUy5zqHnnHoAAAAAAFynwIfiR0ZGytPTU5KUlpamoUOH5roq/meffVZ0EQLIm9UqvfVWdnnIEMlsdm08AAAAJZw1y6q39mWPn4a0GCKzO+MnGFuBEvuIiAinxw8//HCRBgOgEDIypBEjssuRkST2AAAAV5GRlaERa7LHT5FNI0nsYXgFSuyjoqKKKw4AAAAAAFAIBTrHHgAAAAAAlCwk9gAAAAAAGBiJPQAAAAAABkZiDwAAAACAgZHYAwAAAABgYAW6Kj6AEsjTU1q58mIZAAAAefL08NTKh1Y6yoDRkdgDRufhIfXq5eooAAAADMPDzUO9bmH8hNKDQ/EBAAAAADAwZuwBo7NapaVLs8sDBkhms2vjAQAAKOGsWVYtPZg9fhrQaIDM7oyfYGwk9oDRZWRIgwZll++7j8QeAADgKjKyMjToi+zx030N7iOxh+FxKD4AAAAAAAZGYg8AAAAAgIGR2AMAAAAAYGAk9gAAAAAAGJhLE/uvv/5avXv3VrVq1WQymfT55587rY+MjJTJZHJaunfv7tTm77//1oABA+Tv76+yZctq8ODBSkpKcmpz4MABtWvXTl5eXgoKCtKMGTOKe9cAAAAAALguXJrYJycnq0mTJlq4cOEV23Tv3l3x8fGO5YMPPnBaP2DAAB06dEgxMTFauXKlvv76aw0ZMsSxPjExUd26dVPNmjW1b98+zZw5U1OmTNFbb71VbPsFAAAAAMD14tLb3fXo0UM9evTIs42np6cCAwMvu+6HH37Q2rVrtWfPHrVs2VKS9Nprr6lnz56aNWuWqlWrpqVLlyojI0OLFy+WxWJRw4YNFRcXpzlz5jj9AHCp9PR0paenOx4nJiZKkqxWq6xWa2F21XBy9vNG2V9Dc3OTadkySZLdzS37vvYlGH0LxYW+haJwuTuGms1Wx790LxQlvrdcx83upmX3LHOUS9tnQN8qHQry+Znsdru9GGPJN5PJpBUrVujuu+921EVGRurzzz+XxWJRuXLl1KlTJ02bNk0VKlSQJC1evFhPP/20zp4963hOZmamvLy8tHz5ct1zzz0aOHCgEhMTnQ7z37x5szp16qS///5b5cqVyxXLlClTNHXq1Fz1y5Ytk4+PT9HtNAAAAAAAl5GSkqL+/fvr/Pnz8vf3z7OtS2fsr6Z79+7q27evQkJCdPToUf373/9Wjx49tHPnTrm7uyshIUGVK1d2eo6Hh4fKly+vhIQESVJCQoJCQkKc2lSpUsWx7nKJ/cSJEzV27FjH48TERAUFBalbt25XfUNLC6vVqpiYGHXt2lXmy01fAIVE30JxoW+hKDzwQO46s9mq/v1jtGxZV73/Pn0LRYfvLRQX+lbpkHPkeH6U6MT+wQcfdJQbNWqkxo0bq1atWoqNjVXnzp2L7XU9PT3l6emZq95sNt9wfxg34j4bTmamtGJFdvmeeySPEv1n7UDfQnGhb+Fa5HXUo9VK30Lx4Hvr+su0ZWrFD9njp3vq3yMPN2OMnwqKvmVsBfnsDNWDb775ZlWsWFE///yzOnfurMDAQJ0+fdqpTWZmpv7++2/HefmBgYE6deqUU5ucx1c6dx8wlPR06f77s8tJSYZJ7AEAAFwlPTNd93+SPX5KmpgkDwvjJxiboe5j//vvv+uvv/5S1apVJUmhoaE6d+6c9u3b52izadMm2Ww2tW7d2tHm66+/drrwQExMjOrWrXvZw/ABAAAAADASlyb2SUlJiouLU1xcnCTp2LFjiouL04kTJ5SUlKTx48dr165dOn78uDZu3Kg+ffqodu3aCg8PlyTVr19f3bt31+OPP67du3dr+/btGjFihB588EFVq1ZNktS/f39ZLBYNHjxYhw4d0kcffaT58+c7nUMPAAAAAIBRuTSx37t3r5o1a6ZmzZpJksaOHatmzZrp+eefl7u7uw4cOKC77rpLt9xyiwYPHqwWLVpo69atTue/L126VPXq1VPnzp3Vs2dP3XHHHU73qA8ICND69et17NgxtWjRQk8//bSef/75K97qDgAAAAAAI3HpySRhYWHK625769atu+o2ypcvr2X/u4f3lTRu3Fhbt24tcHwAAAAAAJR0hjrHHgAAAAAAOCOxBwAAAADAwLivA2B0FosUFXWxDAAAgDxZ3C2K6hPlKANGR2IPGJ3ZLEVGujoKAAAAwzC7mxXZNNLVYQBFhkPxAQAAAAAwMGbsAaPLzJRy7iARHi558GcNAACQl0xbptb9nD1+Cq8dLg83xk8wNnowYHTp6dKdd2aXk5JI7AEAAK4iPTNdd36QPX5KmpgkDwvjJxgbh+IDAAAAAGBgJPYAAAAAABgYiT0AAAAAAAZGYg8AAAAAgIGR2AMAAAAAYGAk9gAAAAAAGBj3dQCMzmKRFiy4WAYAAECeLO4WLeixwFEGjI7EHjA6s1kaPtzVUQAAABiG2d2s4bcxfkLpwaH4AAAAAAAYGDP2gNFlZUlbt2aX27WT3N1dGw8AAEAJl2XL0tYT2eOndjXayd2N8ROMjcQeMLq0NKljx+xyUpLk6+vaeAAAAEq4tMw0dVySPX5KmpgkXwvjJxgbh+IDAAAAAGBgJPYAAAAAABgYiT0AAAAAAAZGYg8AAAAAgIGR2AMAAAAAYGAk9gAAAAAAGBi3uwOMzmyWZsy4WAYAAECezO5mzegyw1EGjI7EHjA6i0UaP97VUQAAABiGxd2i8W0ZP6H04FB8AAAAAAAMjBl7wOiysqRvv80uN28uubu7Nh4AAIASLsuWpW/js8dPzas2l7sb4ycYG4k9YHRpadJtt2WXk5IkX1/XxgMAAFDCpWWm6ba3s8dPSROT5Gth/ARj41B8AAAAAAAMjMQeAAAAAAADI7EHAAAAAMDASOwBAAAAADAwEnsAAAAAAAyMxB4AAAAAAAPjdneA0ZnN0uTJF8sAAADIk9ndrMkdJjvKgNGR2ANGZ7FIU6a4OgoAAADDsLhbNCVsiqvDAIoMh+IDAAAAAGBgzNgDRmezST/8kF2uX19y4/c6AACAvNjsNv1wJnv8VL9SfbmZGD/B2EjsAaNLTZVuvTW7nJQk+fq6Nh4AAIASLtWaqlvfyB4/JU1Mkq+F8ROMjZ+mAAAAAAAwMBJ7AAAAAAAMjMQeAAAAAAADI7EHAAAAAMDASOwBAAAAADAwEnsAAAAAAAyM290BRmc2S+PGXSwDAAAgT2Z3s8aFjnOUAaNz6Yz9119/rd69e6tatWoymUz6/PPPndbb7XY9//zzqlq1qry9vdWlSxf99NNPTm3+/vtvDRgwQP7+/ipbtqwGDx6spKQkpzYHDhxQu3bt5OXlpaCgIM2YMaO4dw24fiwWaebM7MVicXU0AFCq9e599QVAyWdxt2hmt5ma2W2mLO6Mn2B8Lk3sk5OT1aRJEy1cuPCy62fMmKH//Oc/WrRokb755hv5+voqPDxcaWlpjjYDBgzQoUOHFBMTo5UrV+rrr7/WkCFDHOsTExPVrVs31axZU/v27dPMmTM1ZcoUvfXWW8W+fwAAAAAAFDeXHorfo0cP9ejR47Lr7Ha75s2bp0mTJqlPnz6SpHfffVdVqlTR559/rgcffFA//PCD1q5dqz179qhly5aSpNdee009e/bUrFmzVK1aNS1dulQZGRlavHixLBaLGjZsqLi4OM2ZM8fpBwDAsGw26cSJ7HKNGpIbl84AAADIi81u04nz2eOnGgE15GZi/ARjK7Hn2B87dkwJCQnq0qWLoy4gIECtW7fWzp079eCDD2rnzp0qW7asI6mXpC5dusjNzU3ffPON7rnnHu3cuVPt27eX5ZJDlMPDw/Xqq6/q7NmzKleuXK7XTk9PV3p6uuNxYmKiJMlqtcpqtRbH7pY4Oft5o+yvoSUnyxwSIkmynj0r+fq6OKC80bdQXOhbKAqXu1SJ2Wx1+vdq6ILIL763XCc5I1kh87PHT2fHnZWvpWSPnwqKvlU6FOTzK7GJfUJCgiSpSpUqTvVVqlRxrEtISFDlypWd1nt4eKh8+fJObUL+l/Rcuo2cdZdL7KdPn66pU6fmql+/fr18fHwKuUfGFBMT4+oQcBXuaWm683/ldevWKcvLy6Xx5Bd9C8WFvoVrERFx5XX9++evb61eXUTB4IbB99b1l5Z18dTedevWycvdGOOngqJvGVtKSkq+25bYxN6VJk6cqLFjxzoeJyYmKigoSN26dZO/v78LI7t+rFarYmJi1LVrV5m50nrJlpzsKIaHhxtixp6+heJA30JReOCB3HVms1X9+8do2bKuslqv3rc++qgYAkOpxPeW6yRnJEsHs8vh4eGlcsaevmV8OUeO50eJTewDAwMlSadOnVLVqlUd9adOnVLTpk0dbU6fPu30vMzMTP3999+O5wcGBurUqVNObXIe57T5J09PT3l6euaqN5vNN9wfxo24z4ZzyedjNpsNc8s7+haKC30L1yKvox6tVnO+Enu6HwqK763rz2x3Hj+V1ve/NO/bjaAgn12JvUpESEiIAgMDtXHjRkddYmKivvnmG4WGhkqSQkNDde7cOe3bt8/RZtOmTbLZbGrdurWjzddff+10fkJMTIzq1q172cPwAQAAAAAwEpcm9klJSYqLi1NcXJyk7AvmxcXF6cSJEzKZTBo9erSmTZumL7/8UgcPHtTAgQNVrVo13X333ZKk+vXrq3v37nr88ce1e/dubd++XSNGjNCDDz6oatWqSZL69+8vi8WiwYMH69ChQ/roo480f/58p0PtAQAAAAAwKpceir9371517NjR8Tgn2Y6IiFB0dLSeeeYZJScna8iQITp37pzuuOMOrV27Vl6XXBxs6dKlGjFihDp37iw3Nzf169dP//nPfxzrAwICtH79eg0fPlwtWrRQxYoV9fzzz3OrOwAAAABAqeDSxD4sLEx2u/2K600mk1544QW98MILV2xTvnx5LVu2LM/Xady4sbZu3VroOIESzcNDevLJi2UAAADkycPNQ0+2fNJRBoyOXgwYnaentHChq6MAAAAwDE8PTy3sxfgJpUeJvXgeAAAAAAC4OmbsAaOz26U//8wuV6womUyujQcAAKCEs9vt+jMle/xU0aeiTIyfYHAk9oDRpaRIlStnl5OSJF9f18YDAABQwqVYU1R5Vvb4KWliknwtjJ9gbByKDwAAAACAgZHYAwAAAABgYCT2AAAAAAAYGIk9AAAAAAAGRmIPAAAAAICBkdgDAAAAAGBg3O4OMDoPDyki4mIZAAAAefJw81BEkwhHGTA6ejFgdJ6eUnS0q6MAAAAwDE8PT0XfHe3qMIAiw6H4AAAAAAAYGDP2gNHZ7VJKSnbZx0cymVwbDwAAQAlnt9uVYs0eP/mYfWRi/ASDY8YeMLqUFMnPL3vJSfABAABwRSnWFPlN95PfdD9Hgg8YGTP2AADghtC7t6sjAACgeDBjDwAAAACAgZHYAwAAAABgYCT2AAAAAAAYGIk9AAAAAAAGRmIPAAAAAICBcVV8wOjc3aV7771YBgAAQJ7c3dx1b4N7HWXA6EjsAaPz8pKWL3d1FAAAAIbh5eGl5fcxfkLpwaH4AAAAAAAYGIk9AAAAAAAGRmIPGF1ysmQyZS/Jya6OBgAAoMRLzkiWaapJpqkmJWcwfoLxkdgDAAAAAGBgJPYAAAAAABgYiT0AAAAAAAZGYg8AAAAAgIGR2AMAAAAAYGAk9gAAAAAAGJiHqwMAcI3c3aWePS+WAQAAkCd3N3f1rNPTUQaMjsQeMDovL2nVKldHAQAAYBheHl5a1Z/xE0oPDsUHAAAAAMDASOwBAAAAADAwEnvA6JKTJV/f7CU52dXRAAAAlHjJGcnyfdlXvi/7KjmD8ROMj3PsgdIgJcXVEQAAABhKipXxE0oPZuwBAAAAADAwEnsAAAAAAAyMxB4AAAAAAAPjHHsAAIAi1Lt33uu/+ur6xAEAuHEwYw8AAAAAgIExYw8YnZub1KHDxTIAAADy5GZyU4eaHRxlwOhI7AGj8/aWYmNdHQUAAIBheJu9FRsZ6+owgCLDz1MAAAAAABgYiT0AAAAAAAZWohP7KVOmyGQyOS316tVzrE9LS9Pw4cNVoUIF+fn5qV+/fjp16pTTNk6cOKFevXrJx8dHlStX1vjx45WZmXm9dwUoPsnJUqVK2UtysqujAQAAKPGSM5JVaWYlVZpZSckZjJ9gfCX+HPuGDRtqw4YNjsceHhdDHjNmjFatWqXly5crICBAI0aMUN++fbV9+3ZJUlZWlnr16qXAwEDt2LFD8fHxGjhwoMxms15++eXrvi9AsfnzT1dHAAAAYCh/pjB+QulR4hN7Dw8PBQYG5qo/f/683nnnHS1btkydOnWSJEVFRal+/fratWuX2rRpo/Xr1+vw4cPasGGDqlSpoqZNm+rFF1/UhAkTNGXKFFksluu9OwAAAAAAFKkSn9j/9NNPqlatmry8vBQaGqrp06erRo0a2rdvn6xWq7p06eJoW69ePdWoUUM7d+5UmzZttHPnTjVq1EhVqlRxtAkPD9ewYcN06NAhNWvW7LKvmZ6ervT0dMfjxMRESZLVapXVai2mPS1ZcvbzRtlfQ7NaZXYUrVIJ/8zoWygu9C1cjdl89TaXf57V6d9rRRdFDr63XOfS99xqtcpqKl2fAX2rdCjI51eiE/vWrVsrOjpadevWVXx8vKZOnap27drp+++/V0JCgiwWi8qWLev0nCpVqighIUGSlJCQ4JTU56zPWXcl06dP19SpU3PVr1+/Xj4+Pte4V8YSExPj6hBwFe5pabrzf+V169Ypy8vLpfHkF30LxYW+hSuJiLi25/fvXzR9a/XqItkMShG+t66/tKw0R3ndunXycjfG+Kmg6FvGlpKSku+2JTqx79Gjh6PcuHFjtW7dWjVr1tTHH38sb2/vYnvdiRMnauzYsY7HiYmJCgoKUrdu3eTv719sr1uSWK1WxcTEqGvXrjIXdooD18clF8wLDw+XfH1dGMzV0bdQXOhbeOCB4tmu2WxV//4xWrasq6zWa+9bH31UBEGhVOB7y3WSM5Klg9nl8PBw+VpK9vipoOhbpUPOkeP5UaIT+38qW7asbrnlFv3888/q2rWrMjIydO7cOadZ+1OnTjnOyQ8MDNTu3budtpFz1fzLnbefw9PTU56enrnqzWbzDfeHcSPus+Fc8vmYzebCH2t6ndG3UFzoWzeu4j7i1Go1F0liT/fEP/G9df2Z7c7jp9L6/pfmfbsRFOSzK9G3u/unpKQkHT16VFWrVlWLFi1kNpu1ceNGx/ojR47oxIkTCg0NlSSFhobq4MGDOn36tKNNTEyM/P391aBBg+seP1As3Nykli2zFzdD/UkDAAC4hJvJTS2rtVTLai3lZmL8BOMr0TP248aNU+/evVWzZk2dPHlSkydPlru7ux566CEFBARo8ODBGjt2rMqXLy9/f3+NHDlSoaGhatOmjSSpW7duatCggR555BHNmDFDCQkJmjRpkoYPH37ZGXnAkLy9pT17XB0FAACAYXibvbXnccZPKD1KdGL/+++/66GHHtJff/2lSpUq6Y477tCuXbtUqVIlSdLcuXPl5uamfv36KT09XeHh4Xr99dcdz3d3d9fKlSs1bNgwhYaGytfXVxEREXrhhRdctUsAAAAAABSpEp3Yf/jhh3mu9/Ly0sKFC7Vw4cIrtqlZs6ZWc/lZAAAAAEApxQklgNGlpEjBwdlLAW6JAQAAcKNKsaYoeF6wgucFK8XK+AnGV6Jn7AHkg90u/frrxTIAAADyZLfb9ev5Xx1lwOiYsQcAAAAAwMBI7AEAAAAAMDASewAAAAAADIzEHgAAAAAAAyOxBwAAAADAwLgqPmB0JpPUoMHFMgAAAPJkMpnUoFIDRxkwOhJ7wOh8fKRDh1wdBQAAgGH4mH106EnGTyg9OBQfAAAAAAADI7EHAAAAAMDASOwBo0tJkRo2zF5SUlwdDQAAQImXYk1Rw9cbquHrDZViZfwE4+Mce8Do7Hbp8OGLZQAAAOTJbrfr8JnDjjJgdCT2AAAA11Hv3nmv/+qr6xMHAKD04FB8AAAAAAAMjMQeAAAAAAADI7EHAAAAAMDASOwBAAAAADAwLp4HGJ3JJNWsebEMAACAPJlMJtUMqOkoA0ZHYg8YnY+PdPy4q6MAAAAwDB+zj46PPu7qMIAiw6H4AAAAAAAYGDP2AACgxLvavd8BALiRMWMPGF1qqtSqVfaSmurqaAAAAEq8VGuqWv1fK7X6v1ZKtTJ+gvExYw8Ync0m7d17sQwAAIA82ew27T2511EGjI4ZewAAAAAADIzEHgAAAAAAAyOxBwAAAADAwEjsAQAAAAAwMBJ7AAAAAAAMjKviA6VBxYqujgAAAMBQKvowfkLpQWIPGJ2vr3TmjKujAAAAMAxfi6/OjGf8hNKDxB4AAKAE6d376m2++qr44wAAGAfn2AMAAAAAYGAk9oDRpaZKYWHZS2qqq6MBAAAo8VKtqQqLDlNYdJhSrYyfYHwcig8Ync0mbdlysQwAAIA82ew2bfl1i6MMGB2JPQAAcLn8nFcOAAAuj0PxAQAAAAAwMBJ7AAAAAAAMjMQeAAAAAAADI7EHAAAAAMDAuHgeUBr4+Lg6AgAAAEPxMTN+QulBYg8Yna+vlJzs6igAAAAMw9fiq+R/M35C6UFiDwAAYDBXuz3gV19dnzgAACUDiT0AAChW3KMeAIDixcXzAKNLS5N69cpe0tJcHQ0AAECJl5aZpl7LeqnXsl5Ky2T8BONjxh4wuqwsafXqi2UAAADkKcuWpdU/rXaUAaNjxh4AAAAAAANjxh4AAKCUyc91DbjAHgCUHjfUjP3ChQsVHBwsLy8vtW7dWrt373Z1SAAAAAAAXJMbZsb+o48+0tixY7Vo0SK1bt1a8+bNU3h4uI4cOaLKlSu7OjwAAAyLq94bE7fMA4DS44aZsZ8zZ44ef/xxDRo0SA0aNNCiRYvk4+OjxYsXuzo0AAAAAAAK7YaYsc/IyNC+ffs0ceJER52bm5u6dOminTt35mqfnp6u9PR0x+Pz589Lkv7++29ZrdbiD7gEsFqtSklJ0V9//SWz2ezqcCApMvLy9Z6Zycr5ecr611953vLuStvIER1diMAKKKdvPfDAX7JaL9+3rkcc0tXfj6vJT5xF8Z5fj8/tWt+L/CrOzzY/fSu/rlcfvJrr0X+QH9l9S/pL0o3zf2JRHIlRUr7jikJxxFkc4638/M1fj/83rsfndi37mpyRLP1vyHTvfX/Jw3bl8VNJ6YMFUdrH8tern7vahQsXJEl2u/2qbU32/LQyuJMnT+qmm27Sjh07FBoa6qh/5plntGXLFn3zzTdO7adMmaKpU6de7zABAAAAAHDy22+/qXr16nm2uSFm7Atq4sSJGjt2rOOxzWbT33//rQoVKshkMrkwsusnMTFRQUFB+u233+Tv7+/qcFCK0LdQXOhbKC70LRQX+haKC32rdLDb7bpw4YKqVat21bY3RGJfsWJFubu769SpU071p06dUmBgYK72np6e8vT0dKorW7ZscYZYYvn7+/NlgGJB30JxoW+huNC3UFzoWygu9C3jCwgIyFe7G+LieRaLRS1atNDGjRsddTabTRs3bnQ6NB8AAAAAAKO5IWbsJWns2LGKiIhQy5Ytddttt2nevHlKTk7WoEGDXB0aAAAAAACFdsMk9g888IDOnDmj559/XgkJCWratKnWrl2rKlWquDq0EsnT01OTJ0/OdUoCcK3oWygu9C0UF/oWigt9C8WFvnXjuSGuig8AAAAAQGl1Q5xjDwAAAABAaUViDwAAAACAgZHYAwAAAABgYCT2AAAAAAAYGIk98mXVqlVq3bq1vL29Va5cOd19992uDgmlSHp6upo2bSqTyaS4uDhXhwODO378uAYPHqyQkBB5e3urVq1amjx5sjIyMlwdGgxo4cKFCg4OlpeXl1q3bq3du3e7OiSUAtOnT1erVq1UpkwZVa5cWXfffbeOHDni6rBQCr3yyisymUwaPXq0q0NBMSOxx1V9+umneuSRRzRo0CB999132r59u/r37+/qsFCKPPPMM6pWrZqrw0Ap8d///lc2m01vvvmmDh06pLlz52rRokX697//7erQYDAfffSRxo4dq8mTJ+vbb79VkyZNFB4ertOnT7s6NBjcli1bNHz4cO3atUsxMTGyWq3q1q2bkpOTXR0aSpE9e/bozTffVOPGjV0dCq4DbneHPGVmZio4OFhTp07V4MGDXR0OSqE1a9Zo7Nix+vTTT9WwYUPt379fTZs2dXVYKGVmzpypN954Q7/88ourQ4GBtG7dWq1atdKCBQskSTabTUFBQRo5cqT+9a9/uTg6lCZnzpxR5cqVtWXLFrVv397V4aAUSEpKUvPmzfX6669r2rRpatq0qebNm+fqsFCMmLFHnr799lv98ccfcnNzU7NmzVS1alX16NFD33//vatDQylw6tQpPf7443rvvffk4+Pj6nBQip0/f17ly5d3dRgwkIyMDO3bt09dunRx1Lm5ualLly7auXOnCyNDaXT+/HlJ4nsKRWb48OHq1auX03cYSjcSe+QpZ3ZrypQpmjRpklauXKly5copLCxMf//9t4ujg5HZ7XZFRkZq6NChatmypavDQSn2888/67XXXtMTTzzh6lBgIH/++aeysrJUpUoVp/oqVaooISHBRVGhNLLZbBo9erTatm2rW2+91dXhoBT48MMP9e2332r69OmuDgXXEYn9Depf//qXTCZTnkvOeaqS9Oyzz6pfv35q0aKFoqKiZDKZtHz5chfvBUqi/Pat1157TRcuXNDEiRNdHTIMIr9961J//PGHunfvrvvuu0+PP/64iyIHgCsbPny4vv/+e3344YeuDgWlwG+//aannnpKS5culZeXl6vDwXXEOfY3qDNnzuivv/7Ks83NN9+s7du3q1OnTtq6davuuOMOx7rWrVurS5cueumll4o7VBhMfvvW/fffr6+++komk8lRn5WVJXd3dw0YMEBLliwp7lBhMPntWxaLRZJ08uRJhYWFqU2bNoqOjpabG79lI/8yMjLk4+OjTz75xOlOMBERETp37py++OIL1wWHUmPEiBH64osv9PXXXyskJMTV4aAU+Pzzz3XPPffI3d3dUZeVlSWTySQ3Nzelp6c7rUPp4eHqAOAalSpVUqVKla7arkWLFvL09NSRI0ccib3VatXx48dVs2bN4g4TBpTfvvWf//xH06ZNczw+efKkwsPD9dFHH6l169bFGSIMKr99S8qeqe/YsaPjKCOSehSUxWJRixYttHHjRkdib7PZtHHjRo0YMcK1wcHw7Ha7Ro4cqRUrVig2NpakHkWmc+fOOnjwoFPdoEGDVK9ePU2YMIGkvhQjsUee/P39NXToUE2ePFlBQUGqWbOmZs6cKUm67777XBwdjKxGjRpOj/38/CRJtWrVUvXq1V0REkqJP/74Q2FhYapZs6ZmzZqlM2fOONYFBga6MDIYzdixYxUREaGWLVvqtttu07x585ScnKxBgwa5OjQY3PDhw7Vs2TJ98cUXKlOmjOO6DQEBAfL29nZxdDCyMmXK5LpWg6+vrypUqMA1HEo5Entc1cyZM+Xh4aFHHnlEqampat26tTZt2qRy5cq5OjQAyCUmJkY///yzfv7551w/EnH2GQrigQce0JkzZ/T8888rISFBTZs21dq1a3NdUA8oqDfeeEOSFBYW5lQfFRWlyMjI6x8QAMPjHHsAAAAAAAyMkw4BAAAAADAwEnsAAAAAAAyMxB4AAAAAAAMjsQcAAAAAwMBI7AEAAAAAMDASewAAAAAADIzEHgAAAAAAAyOxBwAAAADAwEjsAQCAYmNjZTKZdO7cuXw/Z8qUKWratGmxxVRQwcHBmjdvnqvDAADguiOxBwDAQBYtWqQyZcooMzPTUZeUlCSz2aywsDCntjnJ+tGjR6+63dtvv13x8fEKCAgo0njDwsI0evToPNs0atRIQ4cOvey69957T56envrzzz+LNC4AAEoTEnsAAAykY8eOSkpK0t69ex11W7duVWBgoL755hulpaU56jdv3qwaNWqoVq1aV92uxWJRYGCgTCZTscSdl8GDB+vDDz9UampqrnVRUVG66667VLFixeseFwAARkFiDwCAgdStW1dVq1ZVbGysoy42NlZ9+vRRSEiIdu3a5VTfsWNHSZLNZtP06dMVEhIib29vNWnSRJ988olT238eiv9///d/CgoKko+Pj+655x7NmTNHZcuWzRXTe++9p+DgYAUEBOjBBx/UhQsXJEmRkZHasmWL5s+fL5PJJJPJpOPHj+d6/sMPP6zU1FR9+umnTvXHjh1TbGysBg8erKNHj6pPnz6qUqWK/Pz81KpVK23YsOGK79Px48dlMpkUFxfnqDt37pxMJpPTe/f999+rR48e8vPzU5UqVfTII49wdAAAwHBI7AEAMJiOHTtq8+bNjsebN29WWFiYOnTo4KhPTU3VN99840jsp0+frnfffVeLFi3SoUOHNGbMGD388MPasmXLZV9j+/btGjp0qJ566inFxcWpa9eueumll3K1O3r0qD7//HOtXLlSK1eu1JYtW/TKK69IkubPn6/Q0FA9/vjjio+PV3x8vIKCgnJto2LFiurTp48WL17sVB8dHa3q1aurW7duSkpKUs+ePbVx40bt379f3bt3V+/evXXixInCvYnKTvQ7deqkZs2aae/evVq7dq1OnTql+++/v9DbBADAFTxcHQAAACiYjh07avTo0crMzFRqaqr279+vDh06yGq1atGiRZKknTt3Kj09XR07dlR6erpefvllbdiwQaGhoZKkm2++Wdu2bdObb76pDh065HqN1157TT169NC4ceMkSbfccot27NihlStXOrWz2WyKjo5WmTJlJEmPPPKINm7cqJdeekkBAQGyWCzy8fFRYGBgnvs0ePBg9ejRQ8eOHVNISIjsdruWLFmiiIgIubm5qUmTJmrSpImj/YsvvqgVK1boyy+/1IgRIwr1Pi5YsEDNmjXTyy+/7KhbvHixgoKC9OOPP+qWW24p1HYBALjemLEHAMBgwsLClJycrD179mjr1q265ZZbVKlSJXXo0MFxnn1sbKxuvvlm1ahRQz///LNSUlLUtWtX+fn5OZZ33333ihfWO3LkiG677Tanun8+lrKvRJ+T1EtS1apVdfr06QLvU9euXVW9enVFRUVJkjZu3KgTJ05o0KBBkrIvEDhu3DjVr19fZcuWlZ+fn3744YdrmrH/7rvvtHnzZqf3pF69epKUrwsOAgBQUjBjDwCAwdSuXVvVq1fX5s2bdfbsWceMe7Vq1RQUFKQdO3Zo8+bN6tSpk6TspFiSVq1apZtuuslpW56entcUi9lsdnpsMplks9kKvB03NzdFRkZqyZIlmjJliqKiotSxY0fdfPPNkqRx48YpJiZGs2bNUu3ateXt7a17771XGRkZV9yeJNntdked1Wp1apOUlKTevXvr1VdfzfX8qlWrFngfAABwFRJ7AAAMqGPHjoqNjdXZs2c1fvx4R3379u21Zs0a7d69W8OGDZMkNWjQQJ6enjpx4sRlD7u/nLp162rPnj1Odf98nB8Wi0VZWVn5ajto0CBNmzZNn332mVasWKG3337bsW779u2KjIzUPffcIyk7Kb/chfhyVKpUSZIUHx+vZs2aSZLThfQkqXnz5vr0008VHBwsDw+GRAAA4+JQfAAADKhjx47atm2b4uLinJL1Dh066M0331RGRobjwnllypTRuHHjNGbMGC1ZskRHjx7Vt99+q9dee01Lliy57PZHjhyp1atXa86cOfrpp5/05ptvas2aNQW+HV5wcLC++eYbHT9+XH/++Wees/khISHq1KmThgwZIk9PT/Xt29exrk6dOvrss88UFxen7777Tv37989zW97e3mrTpo1eeeUV/fDDD9qyZYsmTZrk1Gb48OH6+++/9dBDD2nPnj06evSo1q1bp0GDBuX7xwgAAEoCEnsAAAyoY8eOSk1NVe3atVWlShVHfYcOHXThwgXHbfFyvPjii3ruuec0ffp01a9fX927d9eqVasUEhJy2e23bdtWixYt0pw5c9SkSROtXbtWY8aMkZeXV4HiHDdunNzd3dWgQQNVqlTpqufEDx48WGfPnlX//v2dXmvOnDkqV66cbr/9dvXu3Vvh4eFq3rx5nttavHixMjMz1aJFC40ePVrTpk1zWl+tWjVt375dWVlZ6tatmxo1aqTRo0erbNmyjkP5AQAwApP90pPPAAAAruDxxx/Xf//7X23dutXVoQAAgEtwQhkAALisWbNmqWvXrvL19dWaNWu0ZMkSvf76664OCwAA/AMz9gAA4LLuv/9+xcbG6sKFC7r55ps1cuRIDR061NVhAQCAfyCxBwAAAADAwLgyDAAAAAAABkZiDwAAAACAgZHYAwAAAABgYCT2AAAAAAAYGIk9AAAAAAAGRmIPAAAAAICBkdgDAAAAAGBgJPYAAAAAABjY/wNfKdfHolbjdwAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lower Bound: -4.5580, Upper Bound: 3.2735\n",
            "Quantized weights saved to quantized_weights_int8.npz\n",
            "Quantized Weights:\n",
            "wih: (784, 10), min: -42, max: 47\n",
            "bih: (1, 10), min: -39, max: 19\n",
            "who: (10, 10), min: -128, max: 127\n",
            "bho: (1, 10), min: -128, max: -29\n",
            "Normal weights:\n",
            "wih: (784, 10), min: -1.06289803981781, max: 1.2112243175506592\n",
            "bih: (1, 10), min: -0.9975035786628723, max: 0.49849313497543335\n",
            "who: (10, 10), min: -6.2362213134765625, max: 4.9516777992248535\n",
            "bho: (1, 10), min: -3.4558627605438232, max: -0.7425631880760193\n",
            "Dequantized Weights:\n",
            "wih: (784, 10), min: -1.074114829301834, max: 1.2019856423139572\n",
            "bih: (1, 10), min: -0.9973923414945602, max: 0.4859090894460678\n",
            "who: (10, 10), min: -3.2734928131103516, max: 3.247918650507927\n",
            "bho: (1, 10), min: -3.2734928131103516, max: -0.741650715470314\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def load_weights(filename=\"model_weights.npz\"):\n",
        "    data = np.load(filename)\n",
        "    weights = {\n",
        "        'wih': data['wih'],\n",
        "        'bih': data['bih'],\n",
        "        'who': data['who'],\n",
        "        'bho': data['bho']\n",
        "    }\n",
        "    return weights\n",
        "\n",
        "def plot_histogram(weights, percentage=0.001):\n",
        "    # Concatenate all weights into one flat array\n",
        "    all_weights = np.concatenate([\n",
        "        weights['wih'].flatten(), weights['bih'].flatten(),\n",
        "        weights['who'].flatten(), weights['bho'].flatten()\n",
        "    ])\n",
        "    \n",
        "    # Compute histogram\n",
        "    hist, bin_edges = np.histogram(all_weights, bins=100)\n",
        "    \n",
        "    # Cumulative histogram to find percentiles\n",
        "    cumulative = np.cumsum(hist)\n",
        "    total = cumulative[-1]\n",
        "    \n",
        "    lower_index = np.searchsorted(cumulative, percentage * total)\n",
        "    upper_index = np.searchsorted(cumulative, (1 - percentage) * total)\n",
        "\n",
        "    # Ensure indices are within bounds\n",
        "    lower_index = min(lower_index, len(bin_edges) - 2)\n",
        "    upper_index = min(upper_index, len(bin_edges) - 2)\n",
        "\n",
        "    lower_bound = bin_edges[lower_index]\n",
        "    upper_bound = bin_edges[upper_index]\n",
        "\n",
        "    # Plot histogram\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.hist(all_weights, bins=100, alpha=0.7, color='blue')\n",
        "    plt.axvline(x=lower_bound, color='red', linestyle='dashed', label='Lower Bound')\n",
        "    plt.axvline(x=upper_bound, color='green', linestyle='dashed', label='Upper Bound')\n",
        "    plt.title('Histogram of Model Weights')\n",
        "    plt.xlabel('Weight Value')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Lower Bound: {lower_bound:.4f}, Upper Bound: {upper_bound:.4f}\")\n",
        "    return lower_bound, upper_bound\n",
        "\n",
        "def quantize_INT8(weights, filename=\"quantized_weights_int8.npz\", type_quantization=\"range_tuning\"):\n",
        "    \"\"\"\"Quantize weights to INT8 using range tuning or range tuning with centering.\"\"\"\n",
        "\n",
        "    # Load weights\n",
        "    lower_bound, upper_bound = plot_histogram(weights)\n",
        "\n",
        "    # Copy keys to quantized weights\n",
        "    quantized_weights = {}\n",
        "    scale = 0\n",
        "    zero_point = 0\n",
        "    if type_quantization == \"range_tuning\":\n",
        "        # Xquan = round(x*2^(8-1) / max(|x|))\n",
        "        for key in weights:\n",
        "            quantized_weights[key] = np.clip(np.round(weights[key] * (2**(8-1) / upper_bound)), -128, 127).astype(np.int8)\n",
        "    elif type_quantization == \"range_tuning_centering\":\n",
        "        scale = 2**(8) / (upper_bound - lower_bound)\n",
        "        zero_point = - np.round(lower_bound * scale) - 2**(7)\n",
        "        for key in weights:\n",
        "            quantized_weights[key] = np.clip(np.round(weights[key] * scale + zero_point), -128, 127).astype(np.int8)\n",
        "\n",
        "    # Save quantized weights to file\n",
        "    np.savez(\n",
        "        filename,\n",
        "        wih=quantized_weights['wih'],\n",
        "        bih=quantized_weights['bih'],\n",
        "        who=quantized_weights['who'],\n",
        "        bho=quantized_weights['bho']\n",
        "    )\n",
        "    print(f\"Quantized weights saved to {filename}\")\n",
        "    return quantized_weights, scale, zero_point, lower_bound, upper_bound\n",
        "\n",
        "def dequantize_INT8(quantized_weights, type_quantization=\"range_tuning\", scale=0, zero_point=0, lower_bound=0, upper_bound=0):\n",
        "    \"\"\"Dequantize weights from INT8 back to original values.\"\"\"\n",
        "    dequantized_weights = {}\n",
        "    if type_quantization == \"range_tuning\":\n",
        "        for key in quantized_weights:\n",
        "            dequantized_weights[key] = quantized_weights[key] * (upper_bound / (2**(8-1)))\n",
        "    elif type_quantization == \"range_tuning_centering\":\n",
        "        for key in quantized_weights:\n",
        "            dequantized_weights[key] = (quantized_weights[key] - zero_point) / scale\n",
        "    return dequantized_weights\n",
        "\n",
        "\n",
        "# Load weights from file\n",
        "weights = load_weights(\"weights_fp32.npz\")\n",
        "\n",
        "# Plot histogram and quantize weights\n",
        "quantized_weights, scale, zero_point, lower_bound,  upper_bound = quantize_INT8(weights, filename=\"quantized_weights_int8.npz\")\n",
        "\n",
        "print(\"Quantized Weights:\")\n",
        "for key in quantized_weights:\n",
        "    print(f\"{key}: {quantized_weights[key].shape}, min: {quantized_weights[key].min()}, max: {quantized_weights[key].max()}\")\n",
        "\n",
        "print(\"Normal weights:\")\n",
        "for key in weights:\n",
        "    print(f\"{key}: {weights[key].shape}, min: {weights[key].min()}, max: {weights[key].max()}\")\n",
        "\n",
        "print(\"Dequantized Weights:\")\n",
        "dequantized_weights = dequantize_INT8(quantized_weights, type_quantization=\"range_tuning\", scale=scale, zero_point=zero_point, lower_bound=lower_bound, upper_bound=upper_bound)\n",
        "for key in dequantized_weights:\n",
        "    print(f\"{key}: {dequantized_weights[key].shape}, min: {dequantized_weights[key].min()}, max: {dequantized_weights[key].max()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Quantized Weights and Biases range:\n",
            "INT8 Weights Input-Hidden:  -42 47\n",
            "INT8 Bias Input-Hidden:  -39 19\n",
            "INT8 Weights Hidden-Output:  -128 127\n",
            "INT8 Bias Hidden-Output:  -128 -29\n",
            "\n",
            "Model: FP32\n",
            "Predictions:  [5 8 7 6 4 7 7 4 9 4 1 6 8 6 8 7 9 4 5 6 1 7 1 4 8 9 1 6 8 8 1 1 0 1 7 4 1\n",
            " 6 1 0 6 2 3 0 5 5 4 5 0 3 7 2 5 4 2 1 1 5 5 6 3 5 5 1 0 7 8 9 6 1 5 0 5 0\n",
            " 7 0 1 3 6 1 6 5 1 0 4 0 2 6 0 0 3 6 0 1 5 5 0 3 2 5]\n",
            "Labels:  [3 8 7 6 8 7 7 4 9 4 1 8 2 6 8 7 9 4 5 6 1 7 1 1 8 9 1 6 8 8 2 1 0 1 7 7 1\n",
            " 6 1 6 6 2 3 0 5 5 4 5 0 3 9 2 5 4 2 1 7 5 5 6 3 5 5 1 0 7 8 9 6 1 0 0 5 0\n",
            " 7 0 1 9 6 1 6 5 1 0 4 0 2 6 0 0 3 6 0 1 5 5 0 3 2 3]\n",
            "\n",
            "Model: INT8\n",
            "Predictions:  [2 2 0 0 2 0 2 0 0 1 2 2 2 0 2 2 0 2 0 0 2 0 0 0 2 0 0 0 2 2 2 2 2 2 0 2 2\n",
            " 0 0 1 2 2 0 0 2 2 2 0 0 0 2 2 0 2 0 0 0 2 2 2 1 0 1 0 2 0 0 2 0 1 0 2 2 2\n",
            " 2 0 2 0 0 0 0 2 0 2 2 0 2 2 0 0 2 2 2 2 2 0 2 0 0 2]\n",
            "Labels:  [3 8 7 6 8 7 7 4 9 4 1 8 2 6 8 7 9 4 5 6 1 7 1 1 8 9 1 6 8 8 2 1 0 1 7 7 1\n",
            " 6 1 6 6 2 3 0 5 5 4 5 0 3 9 2 5 4 2 1 7 5 5 6 3 5 5 1 0 7 8 9 6 1 0 0 5 0\n",
            " 7 0 1 9 6 1 6 5 1 0 4 0 2 6 0 0 3 6 0 1 5 5 0 3 2 3]\n",
            "\n",
            "Model Performance Comparison:\n",
            "Model  Forward Time All (ms)  Forward Time One (ms)  Accuracy (%)  Weights Size (MB)\n",
            " FP32                 435.98                 4.3598          87.0               0.03\n",
            " INT8                 399.71                 3.9971          13.0               0.01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Crist\\AppData\\Local\\Temp\\ipykernel_9616\\2825271730.py:36: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-x))\n"
          ]
        }
      ],
      "source": [
        "#Load weights from binary file and create a new model\n",
        "model_int8 = NeuralNetwork(input_size=input_size, hidden_size=h_size, output_size=output_size, dtype=np.int8)\n",
        "model_int8.load_all_weights(\"quantized_weights_int8.npz\")\n",
        "\n",
        "# Print range of quantized weights and biases\n",
        "print(\"\\nQuantized Weights and Biases range:\")\n",
        "print(\"INT8 Weights Input-Hidden: \", model_int8.weights_input_hidden.min(), model_int8.weights_input_hidden.max())\n",
        "print(\"INT8 Bias Input-Hidden: \", model_int8.bias_input_hidden.min(), model_int8.bias_input_hidden.max())\n",
        "print(\"INT8 Weights Hidden-Output: \", model_int8.weights_hidden_output.min(), model_int8.weights_hidden_output.max())\n",
        "print(\"INT8 Bias Hidden-Output: \", model_int8.bias_hidden_output.min(), model_int8.bias_hidden_output.max())\n",
        "\n",
        "# Test the quantized model with the same input data\n",
        "# Input data for testing\n",
        "input_data_fp32 = X_test.astype(np.float32)\n",
        "input_data_int8 = X_test.astype(np.int8)\n",
        "\n",
        "# Test the models with the same input data\n",
        "models = {\n",
        "    \"FP32\": model_fp32,\n",
        "    \"INT8\": model_int8\n",
        "}\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    start_forward = time.time()\n",
        "    output = model.forward(input_data_fp32 if model_name == \"FP32\" else input_data_fp16 if model_name == \"FP16\" else input_data_int8)\n",
        "    end_forward = time.time()\n",
        "\n",
        "    if model_name == \"INT8\":\n",
        "        # Decuantize the output for INT8 model to float32 for accuracy calculation\n",
        "        output = upper_bound * (output.astype(np.float32) / (2**(8-1)))\n",
        "\n",
        "    # Calculate accuracy\n",
        "    predictions = np.argmax(output, axis=1)\n",
        "    accuracy = np.mean(predictions == labels) * 100\n",
        "\n",
        "    print(f\"\\nModel: {model_name}\")\n",
        "    print(\"Predictions: \", predictions)\n",
        "    print(\"Labels: \", labels)\n",
        "\n",
        "    # Get size of weights and biases in MB\n",
        "    weights_size = (model.weights_input_hidden.nbytes + model.bias_input_hidden.nbytes +\n",
        "                    model.weights_hidden_output.nbytes + model.bias_hidden_output.nbytes) / (1024 * 1024)\n",
        "\n",
        "\n",
        "    results.append({\n",
        "        \"Model\": model_name,\n",
        "        \"Forward Time All (ms)\": round((end_forward - start_forward) * 1000, 2),\n",
        "        \"Forward Time One (ms)\": round((end_forward - start_forward) * 1000, 2) / len(X_test),\n",
        "        \"Accuracy (%)\": round(accuracy, 2),\n",
        "        \"Weights Size (MB)\": round(weights_size, 2)\n",
        "    })\n",
        "    \n",
        "\n",
        "# === Display results table ===\n",
        "df = pd.DataFrame(results)\n",
        "print(\"\\nModel Performance Comparison:\")\n",
        "print(df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDh7MZVJEuhd"
      },
      "source": [
        "### Pruning\n",
        "Besides reducing precision for the network weights, we can also decide to eliminate network connections that do not contribute significantly to the model. This can be achieved by simply removing the connections whose weights are closest to zero.\n",
        "\n",
        "In this part of the lab you are asked to generate three pruned versions of the original model by setting to zero some of the weights:\n",
        "\n",
        "\n",
        "*   Set to zero the smallest 10% of weights\n",
        "*   Set to zero the smallest 30% of weights\n",
        "*   Set to zero the smallest 50% of weights\n",
        "\n",
        "Report the accuracy for each model against the estimated memory savings.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aP3szogQIn3I"
      },
      "outputs": [],
      "source": [
        "def prune_model(weights, percentage):\n",
        "  # set to zero the smallest weights, according to the given percentage\n",
        "  weights_pruned = None\n",
        "  pass\n",
        "  return weights_pruned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuLQlI19ItIZ"
      },
      "source": [
        "## Analysis\n",
        "\n",
        "Discuss the following questions based on the lab experiments and the theory studied:\n",
        "\n",
        "\n",
        "*   What are the advantages an disadvantages of storing model weights in different formats?\n",
        "*   How much reduction in model memory requirements can be achieved by each of the versions obtained?\n",
        "*   What are the posible computational advantages of the obtained models and how do they depend on the hardware?\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
