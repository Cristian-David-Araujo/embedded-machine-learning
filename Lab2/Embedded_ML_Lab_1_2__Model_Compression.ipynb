{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SFBFiQlYlva"
      },
      "source": [
        "# Embedded ML - Lab 1.2: Model Compression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svldvvGfmN8q"
      },
      "source": [
        "In this lab you are asked to create a compressed verion of an ANNs model. You are not allowed to use ML libraries such as SciKit-learn, PyTorch or TensorFlow, but you are allowed to use standard libraries such as math, numpy and matplotlib if needed. You are given some code but you are expected to write some more and be able to explain and modify everything. This lab is essential for you to grasp the details of some of the most important techniques for compressing or making ML models more efficient: quantization and pruning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQK0RRRuY3rJ"
      },
      "source": [
        "### Learning outcomes\n",
        "\n",
        "\n",
        "* Explain the basic concepts of compression in ANNs\n",
        "* Apply range tuning and centering when doing quantization\n",
        "* Calculate and analyze the impact of quantization and pruning on memory and computing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8wat6Kxul5R"
      },
      "source": [
        "### Naive quantization\n",
        "Quantization means reducing the precission of model parameters and mainly targets weights, since they represent the most volumne of memory and processing in ANNs.\n",
        "\n",
        "Take the code from the last part of Lab 1.1 (MNIST model) and add methods to export and import weights to and from a binary file, making sure both processes work with your code in such a way that you don't have to train every time you want to run inference, but insted, the wieghts are loaded into the model when needed. Investigate which serialization/desarialization options exist in Python and choose one that you understand.\n",
        "\n",
        "Then, create two additional inference methods: FP16 and INT8. The FP16 method should treat all computations in the network involving the weights, as 16-bit floating-point. The INT8 method should work with 8-bit integers instead. In both cases, use the native datatype conversion methods. Investigate the NumPy methods available to enforce the desired datatypes.\n",
        "\n",
        "Run the two quantized models and compare them with the baseline in terms of model size, accuracy and latency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pOUanY8FngTQ"
      },
      "outputs": [],
      "source": [
        "# COPY HERE YOUR MNIST MODEL CODE\n",
        "import pickle\n",
        "\n",
        "def save_weights_binary(weights):\n",
        "  # store all weights in a binary file using pickle\n",
        "  with open('weights.pkl', 'wb') as f:\n",
        "    pickle.dump(weights, f)\n",
        "\n",
        "def load_weights_binary(weights_file):\n",
        "  # load all weights from a binary file using pickle\n",
        "  with open(weights_file, 'rb') as f:\n",
        "    weights = pickle.load(f)\n",
        "  return weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading MNIST dataset...\n",
            "\n",
            "Training model with 10 hidden neurons...\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "operands could not be broadcast together with shapes (9,7) (9,10) ",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 129\u001b[39m\n\u001b[32m    126\u001b[39m nn = NeuralNetwork(input_size=input_size, hidden_size=h_size, output_size=output_size)\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m# Train the neural network\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m \u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m end_train = time.time()\n\u001b[32m    132\u001b[39m \u001b[38;5;66;03m# Time one forward pass\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 81\u001b[39m, in \u001b[36mNeuralNetwork.train\u001b[39m\u001b[34m(self, x, y, epochs, learning_rate)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m     80\u001b[39m     output = \u001b[38;5;28mself\u001b[39m.forward(x)\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m epoch % \u001b[32m10\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m     83\u001b[39m         error = np.mean(np.square(y - output))\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 66\u001b[39m, in \u001b[36mNeuralNetwork.backward\u001b[39m\u001b[34m(self, x, y, output, learning_rate)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y, output, learning_rate):\n\u001b[32m     65\u001b[39m     \u001b[38;5;66;03m# Backpropagation and weight updates\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     \u001b[38;5;28mself\u001b[39m.error = \u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\n\u001b[32m     67\u001b[39m     d_output = \u001b[38;5;28mself\u001b[39m.error * \u001b[38;5;28mself\u001b[39m.sigmoid_derivative(output)\n\u001b[32m     69\u001b[39m     \u001b[38;5;28mself\u001b[39m.hidden_error = d_output.dot(\u001b[38;5;28mself\u001b[39m.weights_hidden_output.T)\n",
            "\u001b[31mValueError\u001b[39m: operands could not be broadcast together with shapes (9,7) (9,10) "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# === NeuralNetwork class ===\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # Initialize weights and biases\n",
        "        self.weights_input_hidden = np.random.randn(self.input_size, self.hidden_size)* 0.01\n",
        "        self.bias_input_hidden = np.zeros((1, self.hidden_size))\n",
        "        self.weights_hidden_output = np.random.randn(self.hidden_size, self.output_size)* 0.01\n",
        "        self.bias_hidden_output = np.zeros((1, self.output_size))\n",
        "\n",
        "    def my_dot(self, A, B):\n",
        "        # dot product\n",
        "        # complete here the missing code...\n",
        "\n",
        "        # Check if A is 1D and reshape it to 2D for consistency\n",
        "        if A.ndim == 1:\n",
        "            A = A.reshape(1, -1)\n",
        "\n",
        "        # Initialize the result matrix with zeros\n",
        "        result = np.zeros((A.shape[0], B.shape[1]))\n",
        "        for i in range(A.shape[0]):\n",
        "            for j in range(B.shape[1]):\n",
        "                for k in range(A.shape[1]):\n",
        "                    result[i, j] += A[i, k] * B[k, j]\n",
        "        return result\n",
        "    \n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward propagation through the network...\n",
        "\n",
        "        # Step 1: dot product between the input and the weights\n",
        "        # that connect with the hidden layer.\n",
        "        # complete here the missing code...\n",
        "\n",
        "        self.hidden_input = self.my_dot(x, self.weights_input_hidden) + self.bias_input_hidden\n",
        "        self.hidden_output = self.sigmoid(self.hidden_input)\n",
        "        \n",
        "\n",
        "        # Step 2: dot product between the activations (outputs) of the\n",
        "        # hidden layer and the weights that connect with the output layer.\n",
        "        # complete here the missing code...\n",
        "\n",
        "        self.final_input =  self.my_dot(self.hidden_output, self.weights_hidden_output) + self.bias_hidden_output\n",
        "        self.output = self.sigmoid(self.final_input)\n",
        "        \n",
        "        return self.output\n",
        "\n",
        "    def backward(self, x, y, output, learning_rate):\n",
        "        # Backpropagation and weight updates\n",
        "        self.error = y - output\n",
        "        d_output = self.error * self.sigmoid_derivative(output)\n",
        "\n",
        "        self.hidden_error = d_output.dot(self.weights_hidden_output.T)\n",
        "        d_hidden = self.hidden_error * self.sigmoid_derivative(self.hidden_output)\n",
        "\n",
        "        self.weights_hidden_output += self.hidden_output.T.dot(d_output) * learning_rate\n",
        "        self.bias_hidden_output += np.sum(d_output, axis=0, keepdims=True) * learning_rate\n",
        "        self.weights_input_hidden += x.T.dot(d_hidden) * learning_rate\n",
        "        self.bias_input_hidden += np.sum(d_hidden, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    def train(self, x, y, epochs, learning_rate):\n",
        "        error = 0\n",
        "        for epoch in range(epochs):\n",
        "            output = self.forward(x)\n",
        "            self.backward(x, y, output, learning_rate)\n",
        "            if epoch % 10 == 0:\n",
        "                error = np.mean(np.square(y - output))\n",
        "                print(f'Epoch {epoch}: Loss = {error:.4f}')\n",
        "        print(f'Epoch {epochs}: Loss = {error:.4f} ')\n",
        "\n",
        "\n",
        "# === Load and preprocess MNIST dataset ===\n",
        "print(\"Loading MNIST dataset...\")\n",
        "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
        "X_data = mnist.data / 255.0\n",
        "y_data = mnist.target.astype(np.int32)\n",
        "\n",
        "# Reduce dataset size for faster training\n",
        "X_data = X_data[:10]\n",
        "y_data = y_data[:10]\n",
        "\n",
        "# One-hot encode labels\n",
        "encoder = OneHotEncoder(sparse_output=False, categories='auto')\n",
        "y_data_encoded = encoder.fit_transform(y_data.reshape(-1, 1))\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data_encoded, test_size=0.1, random_state=42)\n",
        "\n",
        "# === Run experiments with different hidden layer sizes ===\n",
        "h_size = 10\n",
        "results = []\n",
        "\n",
        "# Define parameters\n",
        "\n",
        " #Number of features (28*28=784)\n",
        "input_size = X_train.shape[1]\n",
        "# Number of classes (based on one-hot encoding)\n",
        "output_size = 10\n",
        "# Number of epochs\n",
        "epochs = 200\n",
        "# Learning rate\n",
        "learning_rate = 0.05\n",
        "\n",
        "\n",
        "print(f\"\\nTraining model with {h_size} hidden neurons...\")\n",
        "nn = NeuralNetwork(input_size=input_size, hidden_size=h_size, output_size=output_size)\n",
        "\n",
        "start_train = time.time()\n",
        "nn.train(X_train, y_train, epochs=epochs, learning_rate=learning_rate)\n",
        "end_train = time.time()\n",
        "\n",
        "# Time one forward pass\n",
        "start_forward = time.time()\n",
        "output = nn.forward(X_test[:1])\n",
        "end_forward = time.time()\n",
        "\n",
        "# Predict and evaluate accuracy\n",
        "predictions = np.argmax(nn.forward(X_test), axis=1)\n",
        "print(\"Predictions: \", predictions)\n",
        "\n",
        "labels = np.argmax(y_test, axis=1)\n",
        "print(\"Labels: \", labels)\n",
        "accuracy = np.mean(predictions == labels) * 100\n",
        "\n",
        "# Count parameters and forward operations\n",
        "param_count = (2 * input_size * h_size) + (2 * h_size * output_size) + (h_size + output_size)\n",
        "forward_ops = 2*input_size*h_size + 3*h_size + 2\n",
        "\n",
        "results.append({\n",
        "    \"Hidden Neurons\": h_size,\n",
        "    \"Parameters\": param_count,\n",
        "    \"Forward Ops\": forward_ops,\n",
        "    \"Training Time (s)\": round(end_train - start_train, 2),\n",
        "    \"Forward Time (ms)\": round((end_forward - start_forward) * 1000, 2),\n",
        "    \"Accuracy (%)\": round(accuracy, 2)\n",
        "})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weights loaded from binary file.\n",
            "Weights and biases:\n",
            "weights_input_hidden: [[-2.63844632e-02]\n",
            " [ 1.16349034e-02]\n",
            " [ 1.15859558e-02]\n",
            " [-1.07652234e-02]\n",
            " [ 2.01325221e-02]\n",
            " [-1.12839139e-03]\n",
            " [ 1.11884251e-02]\n",
            " [-6.39881631e-03]\n",
            " [ 8.27274213e-03]\n",
            " [ 3.14626283e-03]\n",
            " [ 5.65563864e-03]\n",
            " [ 2.39364628e-03]\n",
            " [ 2.08765575e-02]\n",
            " [-3.71191495e-03]\n",
            " [ 8.81994268e-03]\n",
            " [ 2.14848382e-02]\n",
            " [-6.65136127e-03]\n",
            " [ 1.34496627e-03]\n",
            " [-1.01032192e-02]\n",
            " [ 1.36689124e-03]\n",
            " [-1.14263403e-02]\n",
            " [-9.09418261e-03]\n",
            " [-2.57980472e-03]\n",
            " [ 1.29155093e-02]\n",
            " [ 3.97969660e-03]\n",
            " [ 4.96065852e-03]\n",
            " [-1.89374979e-02]\n",
            " [-1.54475399e-02]\n",
            " [ 5.04541680e-03]\n",
            " [-7.67275375e-04]\n",
            " [ 1.53384865e-02]\n",
            " [-1.52935548e-03]\n",
            " [-6.92564544e-03]\n",
            " [ 3.63325166e-03]\n",
            " [ 1.02930808e-02]\n",
            " [-1.92630572e-03]\n",
            " [ 1.03864598e-02]\n",
            " [-1.32548560e-02]\n",
            " [-1.09060095e-02]\n",
            " [-2.07971775e-02]\n",
            " [-1.30623166e-02]\n",
            " [-1.14790191e-02]\n",
            " [ 9.84533905e-03]\n",
            " [ 1.00037441e-02]\n",
            " [-3.69918796e-03]\n",
            " [-5.18424124e-03]\n",
            " [ 1.14560507e-03]\n",
            " [ 1.85934853e-02]\n",
            " [ 3.13047163e-04]\n",
            " [ 1.15273456e-03]\n",
            " [ 2.80871327e-03]\n",
            " [-1.31879850e-02]\n",
            " [ 9.21231188e-03]\n",
            " [-4.77598646e-03]\n",
            " [-6.75995371e-04]\n",
            " [-1.96115232e-02]\n",
            " [-1.00236142e-02]\n",
            " [-3.30593678e-03]\n",
            " [-3.44395666e-03]\n",
            " [-9.79920701e-03]\n",
            " [ 4.51741825e-04]\n",
            " [ 2.16201472e-03]\n",
            " [-1.84728097e-02]\n",
            " [-5.79199956e-03]\n",
            " [-2.02505270e-02]\n",
            " [-1.23013106e-02]\n",
            " [ 1.58541679e-02]\n",
            " [-2.15822117e-02]\n",
            " [ 2.86500097e-03]\n",
            " [-7.35921901e-03]\n",
            " [-1.67784064e-03]\n",
            " [ 4.45411017e-03]\n",
            " [ 1.03838332e-02]\n",
            " [ 1.90935478e-02]\n",
            " [-1.35467636e-02]\n",
            " [-4.50609944e-03]\n",
            " [-4.01534395e-03]\n",
            " [ 1.24510476e-02]\n",
            " [ 8.11836266e-03]\n",
            " [-6.56340776e-03]\n",
            " [-1.26351341e-02]\n",
            " [ 5.28220725e-03]\n",
            " [-2.00189524e-03]\n",
            " [-1.21148136e-02]\n",
            " [-7.77817065e-03]\n",
            " [-5.84707869e-03]\n",
            " [-6.38525552e-03]\n",
            " [ 1.75878841e-02]\n",
            " [-9.98082906e-03]\n",
            " [-4.71656700e-03]\n",
            " [ 1.64650827e-02]\n",
            " [-4.32051820e-03]\n",
            " [ 3.36130403e-03]\n",
            " [-8.73951134e-03]\n",
            " [-6.91230498e-03]\n",
            " [-1.50038208e-02]\n",
            " [ 1.63995033e-02]\n",
            " [ 7.10228944e-03]\n",
            " [-9.79329738e-03]\n",
            " [ 8.97841956e-04]\n",
            " [-6.59499145e-03]\n",
            " [ 3.34505387e-03]\n",
            " [-6.76093949e-03]\n",
            " [ 8.39926075e-04]\n",
            " [ 1.31719627e-02]\n",
            " [-9.45914796e-03]\n",
            " [-1.70373750e-02]\n",
            " [-1.20446177e-02]\n",
            " [ 2.23594163e-03]\n",
            " [-3.51591156e-03]\n",
            " [-1.11640730e-02]\n",
            " [-1.52738574e-02]\n",
            " [ 4.98104771e-03]\n",
            " [ 3.29222595e-03]\n",
            " [-7.61103797e-03]\n",
            " [ 2.46906741e-03]\n",
            " [-7.58361068e-03]\n",
            " [ 3.42015854e-03]\n",
            " [-9.14150679e-03]\n",
            " [ 1.55234160e-03]\n",
            " [ 1.27113632e-02]\n",
            " [-8.26588335e-03]\n",
            " [ 5.26400450e-03]\n",
            " [ 2.79307354e-02]\n",
            " [ 1.79952464e-02]\n",
            " [ 1.05591117e-02]\n",
            " [ 1.10268361e-02]\n",
            " [ 5.83805199e-04]\n",
            " [-9.93486543e-03]\n",
            " [ 2.38899202e-02]\n",
            " [ 2.47931371e-02]\n",
            " [-8.30064745e-03]\n",
            " [ 9.62428941e-03]\n",
            " [-1.60625124e-02]\n",
            " [ 4.33277400e-03]\n",
            " [ 5.60792415e-03]\n",
            " [-8.93355372e-03]\n",
            " [-1.60828560e-02]\n",
            " [-1.78523007e-02]\n",
            " [ 7.07506480e-03]\n",
            " [ 3.17854851e-03]\n",
            " [ 1.78683182e-02]\n",
            " [-1.58358147e-02]\n",
            " [-6.63402709e-04]\n",
            " [ 1.96313051e-02]\n",
            " [-9.30819609e-03]\n",
            " [-9.79078037e-03]\n",
            " [ 2.06915176e-02]\n",
            " [-1.65755091e-03]\n",
            " [-9.31135342e-03]\n",
            " [-8.25350809e-03]\n",
            " [ 1.42981462e-02]\n",
            " [ 3.95247202e-02]\n",
            " [ 2.34991385e-02]\n",
            " [ 2.47843972e-02]\n",
            " [ 9.02727936e-03]\n",
            " [ 3.02397825e-02]\n",
            " [ 2.20545380e-02]\n",
            " [ 4.87388764e-02]\n",
            " [ 3.27234119e-02]\n",
            " [ 3.47124733e-02]\n",
            " [ 3.74035985e-02]\n",
            " [ 3.07478353e-02]\n",
            " [ 1.07166669e-02]\n",
            " [-2.57783235e-03]\n",
            " [ 1.20612701e-02]\n",
            " [ 2.29952635e-02]\n",
            " [-3.87795878e-03]\n",
            " [ 8.85985177e-04]\n",
            " [-1.08163346e-02]\n",
            " [ 6.85672985e-04]\n",
            " [ 2.86204418e-03]\n",
            " [ 1.32456869e-02]\n",
            " [ 5.95932650e-03]\n",
            " [-1.21137125e-02]\n",
            " [ 5.83319373e-03]\n",
            " [ 1.50926158e-02]\n",
            " [ 1.18158359e-02]\n",
            " [ 1.91582278e-02]\n",
            " [ 2.23213651e-02]\n",
            " [ 2.26030030e-02]\n",
            " [ 4.29420769e-02]\n",
            " [ 5.98964777e-02]\n",
            " [ 4.03277188e-02]\n",
            " [ 2.11574174e-02]\n",
            " [ 5.59351677e-02]\n",
            " [ 6.01442783e-02]\n",
            " [ 5.21012169e-02]\n",
            " [ 6.84011249e-02]\n",
            " [ 3.37790477e-02]\n",
            " [ 3.16247709e-02]\n",
            " [ 2.39538532e-03]\n",
            " [ 1.39541604e-02]\n",
            " [ 5.75201315e-03]\n",
            " [-1.25568796e-02]\n",
            " [ 1.96111941e-03]\n",
            " [ 2.13186987e-03]\n",
            " [ 2.37163004e-03]\n",
            " [-6.43314370e-03]\n",
            " [-1.07742054e-02]\n",
            " [ 1.51484154e-02]\n",
            " [ 4.97664621e-03]\n",
            " [ 9.59072460e-03]\n",
            " [-3.23029420e-03]\n",
            " [ 9.86165411e-03]\n",
            " [ 2.86881921e-02]\n",
            " [ 1.73534695e-02]\n",
            " [ 1.37890199e-02]\n",
            " [ 2.08143882e-02]\n",
            " [ 6.18602486e-02]\n",
            " [ 4.62494806e-02]\n",
            " [ 6.14442364e-02]\n",
            " [ 4.25029872e-02]\n",
            " [ 5.02697223e-02]\n",
            " [ 5.72228709e-02]\n",
            " [ 3.70474617e-02]\n",
            " [ 7.58503492e-02]\n",
            " [ 4.08710497e-02]\n",
            " [ 1.07180930e-02]\n",
            " [-4.86877636e-03]\n",
            " [-4.64712003e-03]\n",
            " [ 1.86876736e-02]\n",
            " [ 6.77685017e-03]\n",
            " [ 2.08119707e-03]\n",
            " [-5.72472458e-04]\n",
            " [-1.17445275e-03]\n",
            " [-8.00530025e-04]\n",
            " [ 7.61389525e-03]\n",
            " [ 3.72973802e-02]\n",
            " [ 2.87206683e-02]\n",
            " [ 1.66569166e-02]\n",
            " [ 1.37812764e-02]\n",
            " [ 2.43014629e-02]\n",
            " [ 9.48079730e-03]\n",
            " [ 3.86725638e-02]\n",
            " [ 5.48547294e-02]\n",
            " [ 6.73596195e-02]\n",
            " [ 6.58051795e-02]\n",
            " [ 9.06816327e-02]\n",
            " [ 2.43478565e-02]\n",
            " [ 2.57372196e-02]\n",
            " [ 4.66381721e-02]\n",
            " [ 5.29319955e-02]\n",
            " [ 5.65980738e-02]\n",
            " [ 8.48972454e-02]\n",
            " [ 2.49246078e-02]\n",
            " [-7.08276116e-03]\n",
            " [-7.94973841e-03]\n",
            " [ 5.17311293e-04]\n",
            " [ 7.52640879e-03]\n",
            " [-9.17185200e-03]\n",
            " [-7.46114524e-03]\n",
            " [ 1.12818570e-03]\n",
            " [ 1.39778981e-02]\n",
            " [-3.46364851e-04]\n",
            " [ 1.70362393e-02]\n",
            " [-1.18916100e-03]\n",
            " [ 9.90096356e-03]\n",
            " [-2.11796366e-02]\n",
            " [-8.43245637e-03]\n",
            " [ 2.93178515e-03]\n",
            " [-4.93870785e-03]\n",
            " [ 6.99493963e-03]\n",
            " [ 2.52055976e-02]\n",
            " [ 7.99911511e-02]\n",
            " [ 7.92991851e-02]\n",
            " [ 4.23691691e-02]\n",
            " [ 1.13299392e-02]\n",
            " [ 4.70761329e-02]\n",
            " [ 5.10849408e-02]\n",
            " [ 4.34215521e-02]\n",
            " [ 6.00711355e-02]\n",
            " [ 5.63427397e-02]\n",
            " [ 3.23385062e-02]\n",
            " [ 6.41086339e-03]\n",
            " [-2.21960101e-03]\n",
            " [-6.08187655e-03]\n",
            " [ 7.23701878e-03]\n",
            " [-1.22912008e-03]\n",
            " [-8.18822744e-03]\n",
            " [ 3.77683417e-03]\n",
            " [-4.29954142e-03]\n",
            " [-9.46845865e-03]\n",
            " [ 1.29377553e-02]\n",
            " [ 3.98747983e-03]\n",
            " [-1.26655641e-03]\n",
            " [ 1.24496860e-02]\n",
            " [-3.65388658e-03]\n",
            " [-1.62231066e-02]\n",
            " [ 5.64164557e-03]\n",
            " [ 3.75409296e-02]\n",
            " [ 3.19236888e-02]\n",
            " [ 4.82094340e-02]\n",
            " [ 3.79992825e-02]\n",
            " [ 2.75457673e-02]\n",
            " [ 1.93044410e-02]\n",
            " [ 2.64782939e-02]\n",
            " [ 3.35106660e-02]\n",
            " [ 5.10727586e-02]\n",
            " [ 6.86257619e-02]\n",
            " [ 6.43052784e-02]\n",
            " [ 3.12277821e-02]\n",
            " [ 2.17943949e-03]\n",
            " [-1.11803058e-02]\n",
            " [ 1.56330389e-02]\n",
            " [-2.02610817e-02]\n",
            " [ 1.32372797e-02]\n",
            " [ 1.44595704e-03]\n",
            " [-4.43290653e-03]\n",
            " [ 1.30757971e-02]\n",
            " [ 6.12343551e-03]\n",
            " [ 9.26170678e-03]\n",
            " [ 3.80877014e-02]\n",
            " [ 1.48854254e-02]\n",
            " [ 3.96702824e-03]\n",
            " [-4.28241312e-03]\n",
            " [ 2.37395596e-02]\n",
            " [ 1.41175392e-02]\n",
            " [ 4.90136888e-02]\n",
            " [ 1.60634701e-02]\n",
            " [ 2.91475419e-02]\n",
            " [ 5.70338851e-02]\n",
            " [ 1.31650232e-02]\n",
            " [ 5.46741262e-02]\n",
            " [ 3.98625642e-02]\n",
            " [ 4.35905024e-02]\n",
            " [ 6.28494642e-02]\n",
            " [ 4.84897364e-02]\n",
            " [ 5.75168866e-02]\n",
            " [ 8.74301513e-03]\n",
            " [ 1.17807704e-02]\n",
            " [ 2.91272057e-04]\n",
            " [ 4.47859535e-03]\n",
            " [ 1.26829353e-02]\n",
            " [ 4.02333044e-03]\n",
            " [ 9.56617804e-03]\n",
            " [-2.28697428e-03]\n",
            " [ 2.67511991e-03]\n",
            " [-3.02696429e-03]\n",
            " [ 1.36271034e-02]\n",
            " [ 1.99303302e-02]\n",
            " [ 1.61502358e-02]\n",
            " [-5.01892800e-03]\n",
            " [-4.09897936e-05]\n",
            " [ 1.97980991e-02]\n",
            " [ 1.67980139e-02]\n",
            " [ 2.20606567e-02]\n",
            " [ 1.78736369e-02]\n",
            " [ 2.02203301e-02]\n",
            " [ 2.40868821e-02]\n",
            " [ 4.66910951e-02]\n",
            " [ 6.43481435e-02]\n",
            " [ 4.04202429e-02]\n",
            " [ 4.13483694e-02]\n",
            " [ 7.77268250e-02]\n",
            " [ 5.52807873e-02]\n",
            " [ 4.68569749e-02]\n",
            " [ 5.75108254e-03]\n",
            " [ 2.63721694e-02]\n",
            " [-1.53634430e-02]\n",
            " [ 6.34801212e-03]\n",
            " [ 1.44129660e-02]\n",
            " [-4.24907442e-03]\n",
            " [-4.30405653e-03]\n",
            " [ 1.71716819e-02]\n",
            " [-1.70486310e-02]\n",
            " [-6.27853592e-03]\n",
            " [ 2.81592175e-02]\n",
            " [ 3.62268669e-02]\n",
            " [-2.65988780e-04]\n",
            " [ 2.40363174e-03]\n",
            " [ 2.08403555e-02]\n",
            " [ 2.36784459e-02]\n",
            " [ 3.37520975e-02]\n",
            " [ 1.11603207e-02]\n",
            " [ 2.75799310e-02]\n",
            " [ 3.94967539e-03]\n",
            " [ 5.16263728e-02]\n",
            " [ 4.96982876e-02]\n",
            " [ 8.21317026e-02]\n",
            " [ 6.57296326e-02]\n",
            " [ 6.05352139e-02]\n",
            " [ 6.87656822e-02]\n",
            " [ 4.94861475e-02]\n",
            " [ 1.73116030e-02]\n",
            " [ 1.38591887e-02]\n",
            " [ 3.68833443e-03]\n",
            " [-6.05997173e-03]\n",
            " [-4.26616696e-03]\n",
            " [ 1.03404885e-02]\n",
            " [-6.29864368e-03]\n",
            " [-1.27968566e-02]\n",
            " [-5.32122622e-03]\n",
            " [-8.88449691e-04]\n",
            " [ 4.70557015e-03]\n",
            " [ 2.35407668e-02]\n",
            " [ 3.90143250e-02]\n",
            " [ 5.50490658e-03]\n",
            " [-3.36167964e-03]\n",
            " [ 1.47980932e-02]\n",
            " [ 2.38564545e-02]\n",
            " [ 3.17605952e-02]\n",
            " [ 3.26433563e-02]\n",
            " [ 1.97508244e-02]\n",
            " [ 4.37615907e-02]\n",
            " [ 9.45157331e-02]\n",
            " [ 1.05974965e-01]\n",
            " [ 9.74579183e-02]\n",
            " [ 8.75915594e-02]\n",
            " [ 5.95289545e-02]\n",
            " [ 3.49625181e-02]\n",
            " [ 1.99409216e-02]\n",
            " [ 7.98546003e-03]\n",
            " [ 1.27733366e-02]\n",
            " [-3.02621190e-03]\n",
            " [-2.07035867e-03]\n",
            " [ 9.22107184e-03]\n",
            " [ 4.98948943e-03]\n",
            " [ 2.41753422e-05]\n",
            " [ 3.86896073e-03]\n",
            " [-1.12453683e-02]\n",
            " [ 1.68435442e-02]\n",
            " [ 1.32431622e-02]\n",
            " [ 2.57573513e-02]\n",
            " [ 1.09303265e-02]\n",
            " [ 3.17299075e-03]\n",
            " [ 1.42039423e-02]\n",
            " [ 5.57539721e-02]\n",
            " [ 5.39043088e-02]\n",
            " [ 6.49161912e-02]\n",
            " [ 7.20719437e-02]\n",
            " [ 8.75079274e-02]\n",
            " [ 9.06774436e-02]\n",
            " [ 9.00552597e-02]\n",
            " [ 9.08323064e-02]\n",
            " [ 8.86992840e-02]\n",
            " [ 5.93093418e-02]\n",
            " [ 4.78110930e-02]\n",
            " [ 4.73046354e-02]\n",
            " [ 5.61046973e-03]\n",
            " [ 1.76997966e-02]\n",
            " [ 1.07999117e-02]\n",
            " [ 1.71394711e-02]\n",
            " [ 9.57911076e-03]\n",
            " [-1.55104251e-02]\n",
            " [ 4.08430556e-03]\n",
            " [ 9.67233876e-03]\n",
            " [ 1.00313485e-02]\n",
            " [-9.81954393e-03]\n",
            " [ 9.73044272e-03]\n",
            " [ 1.12382466e-03]\n",
            " [-1.31630738e-03]\n",
            " [ 1.83100240e-02]\n",
            " [ 2.30654484e-02]\n",
            " [ 3.23841924e-02]\n",
            " [ 3.93241893e-02]\n",
            " [ 4.12285173e-02]\n",
            " [ 5.16402345e-02]\n",
            " [ 2.25445514e-02]\n",
            " [ 5.23250498e-02]\n",
            " [ 2.91730539e-02]\n",
            " [ 4.31498498e-02]\n",
            " [ 7.49009267e-02]\n",
            " [ 5.91327633e-02]\n",
            " [ 5.35411359e-02]\n",
            " [ 2.89277412e-02]\n",
            " [ 6.28420769e-02]\n",
            " [ 3.75394701e-02]\n",
            " [ 1.74304098e-02]\n",
            " [ 2.45066691e-03]\n",
            " [-5.56552345e-03]\n",
            " [ 9.91569712e-04]\n",
            " [ 6.72267295e-03]\n",
            " [ 1.12030208e-02]\n",
            " [-5.25458068e-03]\n",
            " [ 1.74694563e-03]\n",
            " [-1.02638168e-03]\n",
            " [-1.26035277e-02]\n",
            " [ 5.60867247e-03]\n",
            " [-6.25542804e-03]\n",
            " [-1.87764563e-02]\n",
            " [-8.80599623e-03]\n",
            " [ 1.37374076e-02]\n",
            " [ 4.02616407e-02]\n",
            " [ 2.07291257e-02]\n",
            " [ 9.19173390e-03]\n",
            " [ 1.79971581e-03]\n",
            " [ 2.18405902e-02]\n",
            " [ 1.62820106e-02]\n",
            " [ 6.04677146e-02]\n",
            " [ 9.10468077e-02]\n",
            " [ 5.41715232e-02]\n",
            " [ 7.03975850e-02]\n",
            " [ 5.09539545e-02]\n",
            " [ 6.96535535e-02]\n",
            " [ 3.95812937e-02]\n",
            " [ 8.84635384e-03]\n",
            " [ 5.17814539e-03]\n",
            " [ 1.51188626e-02]\n",
            " [-3.59256077e-03]\n",
            " [ 2.36185466e-02]\n",
            " [-1.17083792e-02]\n",
            " [ 2.19520958e-02]\n",
            " [-3.52438109e-05]\n",
            " [ 1.19273553e-02]\n",
            " [-7.78348242e-03]\n",
            " [-2.42905613e-02]\n",
            " [ 8.17117048e-03]\n",
            " [ 3.13394080e-04]\n",
            " [-1.99941566e-03]\n",
            " [ 1.04556213e-02]\n",
            " [ 1.76412176e-02]\n",
            " [ 3.16296017e-02]\n",
            " [ 1.19723860e-02]\n",
            " [ 1.72584314e-02]\n",
            " [ 2.76949677e-02]\n",
            " [ 5.13893532e-02]\n",
            " [ 4.59943006e-02]\n",
            " [ 5.44354568e-02]\n",
            " [ 3.78929893e-02]\n",
            " [ 3.60444090e-02]\n",
            " [ 6.88257831e-02]\n",
            " [ 6.02417894e-02]\n",
            " [ 1.14071134e-02]\n",
            " [ 1.10955851e-02]\n",
            " [ 1.27263681e-02]\n",
            " [ 4.22763378e-03]\n",
            " [-8.86232062e-03]\n",
            " [-8.51399579e-03]\n",
            " [-1.15070270e-02]\n",
            " [-1.52005821e-02]\n",
            " [-9.02090388e-03]\n",
            " [-1.54600311e-02]\n",
            " [-1.33636250e-03]\n",
            " [ 5.22512148e-04]\n",
            " [ 3.21678189e-03]\n",
            " [ 8.83608274e-03]\n",
            " [ 6.61977657e-03]\n",
            " [ 1.00297966e-02]\n",
            " [ 6.39028321e-03]\n",
            " [-6.59755482e-03]\n",
            " [-3.07550371e-03]\n",
            " [ 2.60037131e-02]\n",
            " [ 3.25375174e-02]\n",
            " [ 3.76509087e-02]\n",
            " [ 5.55114185e-02]\n",
            " [ 7.26848733e-02]\n",
            " [ 4.92444474e-02]\n",
            " [ 5.37436871e-02]\n",
            " [ 6.46249206e-02]\n",
            " [ 5.47880090e-02]\n",
            " [ 2.23011933e-02]\n",
            " [ 9.10060001e-03]\n",
            " [ 1.13264364e-02]\n",
            " [ 1.21855530e-02]\n",
            " [ 1.31152369e-02]\n",
            " [-1.28366398e-02]\n",
            " [-3.18421550e-03]\n",
            " [-1.50541871e-02]\n",
            " [-2.15387687e-02]\n",
            " [-1.45171605e-02]\n",
            " [ 7.67950278e-03]\n",
            " [-5.21318993e-03]\n",
            " [-1.45404090e-02]\n",
            " [-1.27140296e-02]\n",
            " [ 3.06996688e-03]\n",
            " [ 1.53858918e-02]\n",
            " [ 2.65290894e-02]\n",
            " [ 3.07627620e-02]\n",
            " [ 2.98359851e-02]\n",
            " [ 2.60002893e-02]\n",
            " [ 4.20953338e-02]\n",
            " [ 7.62420824e-02]\n",
            " [ 4.85874140e-02]\n",
            " [ 4.49043447e-02]\n",
            " [ 6.31656594e-02]\n",
            " [ 3.68168262e-02]\n",
            " [ 6.73645567e-02]\n",
            " [ 3.44905833e-02]\n",
            " [ 6.53691743e-04]\n",
            " [-3.89882778e-04]\n",
            " [ 1.49518354e-03]\n",
            " [ 1.46780636e-02]\n",
            " [-9.81790729e-03]\n",
            " [ 1.13817508e-02]\n",
            " [ 4.84091777e-03]\n",
            " [-5.40210799e-03]\n",
            " [-1.67664043e-03]\n",
            " [-1.43903718e-02]\n",
            " [-1.14655764e-02]\n",
            " [ 1.10099311e-02]\n",
            " [ 9.13945479e-03]\n",
            " [-4.18899651e-03]\n",
            " [ 1.23408970e-02]\n",
            " [ 2.59592656e-02]\n",
            " [ 3.06728794e-02]\n",
            " [ 3.45511995e-02]\n",
            " [ 3.62409985e-02]\n",
            " [ 5.37360783e-02]\n",
            " [ 6.30043042e-02]\n",
            " [ 3.40158025e-02]\n",
            " [ 3.75546268e-02]\n",
            " [ 5.57121895e-02]\n",
            " [ 5.78180075e-02]\n",
            " [ 2.98712388e-02]\n",
            " [ 4.96041822e-02]\n",
            " [ 2.60253395e-02]\n",
            " [ 9.13349333e-03]\n",
            " [ 7.94315699e-03]\n",
            " [ 2.27484943e-03]\n",
            " [-4.38636678e-03]\n",
            " [-8.18619763e-03]\n",
            " [-1.05287047e-02]\n",
            " [-9.21818673e-03]\n",
            " [ 6.15525568e-03]\n",
            " [-1.12602572e-02]\n",
            " [ 5.93419568e-03]\n",
            " [ 1.52869781e-02]\n",
            " [ 3.39744263e-03]\n",
            " [ 8.80595233e-03]\n",
            " [-1.61684165e-02]\n",
            " [ 9.81530138e-03]\n",
            " [ 1.54581270e-02]\n",
            " [ 4.61391283e-02]\n",
            " [ 3.16622569e-02]\n",
            " [ 5.59452267e-02]\n",
            " [ 3.92923746e-02]\n",
            " [ 6.91829121e-02]\n",
            " [ 3.91273730e-02]\n",
            " [ 4.33272767e-02]\n",
            " [ 3.97232495e-02]\n",
            " [ 4.51852613e-02]\n",
            " [ 3.28126653e-02]\n",
            " [ 3.48301095e-02]\n",
            " [ 2.10920988e-02]\n",
            " [ 1.81682724e-02]\n",
            " [ 1.05728220e-02]\n",
            " [-1.92602166e-03]\n",
            " [ 8.01208874e-03]\n",
            " [-1.79587937e-02]\n",
            " [-3.51034056e-03]\n",
            " [ 1.23997748e-02]\n",
            " [ 1.43713264e-02]\n",
            " [ 1.55024569e-02]\n",
            " [-1.34947373e-02]\n",
            " [-3.50325869e-03]\n",
            " [-3.47225203e-03]\n",
            " [-6.67278965e-03]\n",
            " [ 1.51600363e-02]\n",
            " [-8.47697280e-04]\n",
            " [ 7.82659920e-03]\n",
            " [ 1.53807432e-02]\n",
            " [ 4.12085233e-02]\n",
            " [ 3.39939931e-02]\n",
            " [ 6.36077591e-02]\n",
            " [ 5.93373208e-02]\n",
            " [ 2.89587773e-02]\n",
            " [ 1.31150954e-02]\n",
            " [ 2.02981056e-02]\n",
            " [ 9.28674341e-03]\n",
            " [ 2.76871400e-02]\n",
            " [ 4.34960510e-02]\n",
            " [ 4.20723839e-02]\n",
            " [ 1.26636441e-02]\n",
            " [-5.41589545e-03]\n",
            " [-1.24265543e-03]\n",
            " [-1.11227169e-02]\n",
            " [ 2.49370298e-04]\n",
            " [-5.89602796e-03]\n",
            " [ 3.93254597e-04]\n",
            " [ 1.88685344e-03]\n",
            " [ 1.19514931e-02]\n",
            " [ 7.14715370e-03]\n",
            " [-7.99071327e-03]\n",
            " [ 4.50455153e-03]\n",
            " [ 1.95028567e-02]\n",
            " [-1.49178002e-02]\n",
            " [ 7.88772750e-03]\n",
            " [-4.32275958e-03]\n",
            " [ 1.82052375e-02]\n",
            " [ 1.72608336e-02]\n",
            " [ 2.58450418e-02]\n",
            " [ 3.37516766e-02]\n",
            " [ 3.36085318e-02]\n",
            " [-1.56075440e-02]\n",
            " [ 1.77085764e-02]\n",
            " [ 1.09331616e-02]\n",
            " [ 1.96121906e-02]\n",
            " [ 9.68624782e-03]\n",
            " [ 1.11562480e-02]\n",
            " [ 2.87185402e-02]\n",
            " [ 1.12947638e-02]\n",
            " [-8.07100605e-03]\n",
            " [ 1.09726154e-02]\n",
            " [ 1.23089915e-02]\n",
            " [ 1.21291715e-02]\n",
            " [ 1.56663774e-02]\n",
            " [-1.76780378e-02]\n",
            " [ 8.03771120e-03]\n",
            " [-2.81711321e-02]\n",
            " [ 3.63032238e-04]\n",
            " [ 6.68482489e-03]\n",
            " [ 1.32626437e-02]\n",
            " [-1.34758931e-02]\n",
            " [-2.10567288e-02]\n",
            " [ 6.52155977e-03]\n",
            " [-5.57926026e-03]\n",
            " [-1.21876489e-02]\n",
            " [ 1.10341661e-02]\n",
            " [ 3.27045131e-03]\n",
            " [-4.62475288e-03]\n",
            " [-6.84801293e-03]\n",
            " [ 1.86926806e-04]\n",
            " [-4.14289859e-03]\n",
            " [ 3.50669247e-03]\n",
            " [ 2.04490981e-02]\n",
            " [ 1.98914048e-02]\n",
            " [ 1.30161745e-02]\n",
            " [ 2.87242192e-03]\n",
            " [-2.03961715e-02]\n",
            " [-4.12338103e-03]\n",
            " [-1.07964293e-02]\n",
            " [-1.34941466e-03]\n",
            " [-1.96323600e-02]\n",
            " [-8.81059284e-03]\n",
            " [ 3.65717638e-03]\n",
            " [-7.54634189e-03]\n",
            " [ 1.24763104e-02]\n",
            " [ 9.54460855e-04]\n",
            " [ 1.21513482e-02]\n",
            " [-8.02810047e-03]\n",
            " [ 2.25348987e-03]\n",
            " [-2.52442742e-03]\n",
            " [ 8.57688484e-03]\n",
            " [ 4.86359030e-03]\n",
            " [-6.99839045e-03]\n",
            " [-4.08576484e-03]\n",
            " [ 1.46914832e-02]\n",
            " [ 1.19062700e-03]\n",
            " [-1.94046039e-02]\n",
            " [-3.33110540e-05]\n",
            " [ 8.46434870e-03]\n",
            " [-2.09715717e-03]\n",
            " [ 3.86112403e-03]\n",
            " [ 1.15486242e-03]\n",
            " [ 1.00810607e-02]\n",
            " [-1.05657671e-03]\n",
            " [-2.11586182e-03]\n",
            " [-4.28395798e-03]\n",
            " [-4.64995817e-03]\n",
            " [-1.72496275e-03]\n",
            " [-6.75769252e-03]\n",
            " [ 1.04120916e-02]\n",
            " [ 8.23568711e-03]\n",
            " [ 3.49159171e-03]\n",
            " [-1.90678805e-02]\n",
            " [ 2.11519973e-02]\n",
            " [-6.89863398e-03]\n",
            " [ 1.23773205e-03]\n",
            " [-1.56709399e-03]\n",
            " [-5.67652598e-03]\n",
            " [ 1.98947425e-02]\n",
            " [ 4.32784123e-03]\n",
            " [-4.65521047e-03]\n",
            " [-3.26682845e-03]\n",
            " [ 2.31402179e-04]\n",
            " [ 6.73807431e-03]\n",
            " [-5.51460163e-04]\n",
            " [ 1.04840109e-02]\n",
            " [ 2.25636393e-02]\n",
            " [-1.81482062e-03]\n",
            " [ 6.50926880e-03]\n",
            " [ 1.14908545e-02]\n",
            " [-4.08916243e-03]\n",
            " [-4.48114305e-03]\n",
            " [-6.12596016e-03]\n",
            " [ 8.54000744e-03]\n",
            " [ 1.11650444e-04]\n",
            " [-3.71129901e-03]\n",
            " [ 2.37154972e-02]\n",
            " [ 1.56512520e-03]\n",
            " [-7.59545184e-03]\n",
            " [ 1.28307076e-02]\n",
            " [ 6.14584911e-04]]\n",
            "bias_input_hidden: [[0.1298655]]\n",
            "weights_hidden_output: [[-0.90507294 -0.60521818 -0.90123197 -0.88993384 -0.5903925  -0.90539006\n",
            "  -0.90486354]]\n",
            "bias_hidden_output: [[-1.08781513 -0.65643237 -1.09187351 -1.10297556 -0.670103   -1.08760315\n",
            "  -1.0878833 ]]\n"
          ]
        }
      ],
      "source": [
        "#Save weights like binary file one file (weights.pkl) with all weights and bias(input, hidden, output)\n",
        "save_weights_binary({\n",
        "    \"weights_input_hidden\": nn.weights_input_hidden,\n",
        "    \"bias_input_hidden\": nn.bias_input_hidden,\n",
        "    \"weights_hidden_output\": nn.weights_hidden_output,\n",
        "    \"bias_hidden_output\": nn.bias_hidden_output\n",
        "})\n",
        "\n",
        "#Load weights from binary file\n",
        "weights = load_weights_binary('weights.pkl')\n",
        "print(\"Weights loaded from binary file.\")\n",
        "print(\"Weights and biases:\")\n",
        "print(\"weights_input_hidden:\", weights[\"weights_input_hidden\"])\n",
        "print(\"bias_input_hidden:\", weights[\"bias_input_hidden\"])\n",
        "print(\"weights_hidden_output:\", weights[\"weights_hidden_output\"])\n",
        "print(\"bias_hidden_output:\", weights[\"bias_hidden_output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpQD3Y7a_wFa"
      },
      "source": [
        "### Range tuning and centering\n",
        "For quantization to be effective, you should smartly choose the range of numbers you will code with the fewer bits available after quantization. To do so, you should evaluate the dynamic ranges of the variables to be quantized and map the values using that as the full range.\n",
        "\n",
        "Make a histogram plot of the model weights in order to verify their range. Then write a function to quantize the weights stored in the exported binary file to INT8 and store the resulting weights in another file. Finally, run again the INT8 quantized inference with the newly computed weights and compare with the previous versions using the same metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDMywPk5qZiV"
      },
      "outputs": [],
      "source": [
        "def plot_histogram(weights):\n",
        "  # plot a histogram of all model weights\n",
        "  pass\n",
        "\n",
        "def quantize_INT8(weights):\n",
        "  # quantize to INT8 the model weights\n",
        "  weights_int8 = None\n",
        "  return weights_int8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDh7MZVJEuhd"
      },
      "source": [
        "### Pruning\n",
        "Besides reducing precision for the network weights, we can also decide to eliminate network connections that do not contribute significantly to the model. This can be achieved by simply removing the connections whose weights are closest to zero.\n",
        "\n",
        "In this part of the lab you are asked to generate three pruned versions of the original model by setting to zero some of the weights:\n",
        "\n",
        "\n",
        "*   Set to zero the smallest 10% of weights\n",
        "*   Set to zero the smallest 30% of weights\n",
        "*   Set to zero the smallest 50% of weights\n",
        "\n",
        "Report the accuracy for each model against the estimated memory savings.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aP3szogQIn3I"
      },
      "outputs": [],
      "source": [
        "def prune_model(weights, percentage):\n",
        "  # set to zero the smallest weights, according to the given percentage\n",
        "  weights_pruned = None\n",
        "  pass\n",
        "  return weights_pruned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuLQlI19ItIZ"
      },
      "source": [
        "## Analysis\n",
        "\n",
        "Discuss the following questions based on the lab experiments and the theory studied:\n",
        "\n",
        "\n",
        "*   What are the advantages an disadvantages of storing model weights in different formats?\n",
        "*   How much reduction in model memory requirements can be achieved by each of the versions obtained?\n",
        "*   What are the posible computational advantages of the obtained models and how do they depend on the hardware?\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
